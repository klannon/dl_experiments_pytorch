{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector to Vector Squared Network & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'vtov2_dataset.npz'\n",
    "batch_size = 250\n",
    "n_epochs = 500\n",
    "hidden_layers = [(1,50)]\n",
    "valid_size = 2000\n",
    "model_path = 'vtov2_model_1'\n",
    "fig_path = 'vtov2_fig_1.png'\n",
    "fig2_path = 'vtov2_fig_2.png'\n",
    "df_path = 'vtov2_df_1'\n",
    "seed = np.random.randint(low=0, high=1000000, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npfile = np.load(infile)\n",
    "inputs = npfile['inputs']\n",
    "outputs = npfile['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing inputs, outputs and coverting to tensors\n",
    "inputMeans = inputs[0:int(inputs.shape[0]),:].mean(axis=0)\n",
    "inputStdDevs = inputs[0:int(inputs.shape[0]),:].std(axis=0)\n",
    "inputs = (inputs-inputMeans)/inputStdDevs\n",
    "inputs = torch.from_numpy(inputs).float()\n",
    "\n",
    "outputMeans = outputs[0:int(outputs.shape[0]),:].mean(axis=0)\n",
    "outputStdDevs = outputs[0:int(outputs.shape[0]),:].std(axis=0)\n",
    "outputs = (outputs-outputMeans)/outputStdDevs\n",
    "outputs = torch.from_numpy(outputs).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a TensorDataset for training\n",
    "trainset = torch.utils.data.TensorDataset(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input, output sizes\n",
    "out_size = list(outputs[0].size())[0]\n",
    "in_size = list(inputs[0].size())[0]\n",
    "\n",
    "# number of hidden layers\n",
    "num = len(hidden_layers)\n",
    "\n",
    "# number of nodes in a given hidden layer\n",
    "def nodes(i):\n",
    "    layer = hidden_layers[i]\n",
    "    dim_node = layer[1]\n",
    "    return dim_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = OrderedDict([])\n",
    "\n",
    "network = OrderedDict([('lin1', nn.Linear(in_size, nodes(0))),('relu1', nn.PReLU())]) \n",
    "if num > 1:\n",
    "    for i in range(1, num):\n",
    "        network['lin{index}'.format(index=i+1)] = nn.Linear(nodes(i-1), nodes(i))\n",
    "        network['relu{index}'.format(index=i+1)] = nn.PReLU()\n",
    "network['lin{index}'.format(index=num+1)] = nn.Linear(nodes(num-1), out_size)    \n",
    "\n",
    "model = nn.Sequential(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the training process for one epoch, returns training loss for given epoch\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # put model into train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (inputs, outputs) in enumerate(loader):\n",
    "        inputs_var = inputs\n",
    "        outputs_var = outputs\n",
    "        \n",
    "        # get model output & loss for each given input\n",
    "        model_outputs = model(inputs_var)\n",
    "        loss = criterion(model_outputs, outputs_var)\n",
    "\n",
    "        # record cummulative loss\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "        # gradient, optimizer steps\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return running_train_loss\n",
    "\n",
    "\n",
    "# defines the validation process for one epoch, returns validation loss for given epoch\n",
    "def validate(model, loader, criterion):\n",
    "    running_valid_loss = 0.0\n",
    "\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (inputs, outputs) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            inputs_var = inputs\n",
    "            outputs_var = outputs\n",
    "\n",
    "            # get model output & loss for each given input\n",
    "            model_outputs = model(inputs_var)\n",
    "            loss = criterion(model_outputs, outputs_var)\n",
    "\n",
    "        # record cummulative loss\n",
    "        running_valid_loss += loss.item()\n",
    "\n",
    "    return running_valid_loss\n",
    "\n",
    "\n",
    "# runs training and validation process over all epochs, returns results\n",
    "def run_training(model, modelpath, figpath, fig2path, dfpath, trainset, validsize, numepochs, batchsize, seed):\n",
    "    # set seed\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # create validation split\n",
    "    indices = torch.randperm(len(trainset))\n",
    "    train_indices = indices[:len(indices) - valid_size]\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "    valid_indices = indices[len(indices) - valid_size:]\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "    # define data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=valid_sampler)\n",
    "  \n",
    "    # set criterion, optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # store results\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    train_loss_results = []\n",
    "    valid_loss_results = []\n",
    "    epochs = []\n",
    "    \n",
    "    # train model\n",
    "    for epoch in enumerate(range(n_epochs)):\n",
    "        trainloss = train(model=model,loader=train_loader,criterion=criterion,optimizer=optimizer)\n",
    "        print('train loss for epoch {index} attained: {loss}'.format(index=epoch[0], loss=trainloss))\n",
    "        \n",
    "        validloss = validate(model=model,loader=valid_loader,criterion=criterion)\n",
    "        print('valid loss for epoch {index} attained: {loss}'.format(index=epoch[0], loss=validloss))\n",
    "        \n",
    "        train_loss_results.append(trainloss)\n",
    "        valid_loss_results.append(validloss)\n",
    "        epochs.append(epoch[0]+1)\n",
    "        \n",
    "        # check if model is the best, save if best\n",
    "        if epoch[0] == 0:\n",
    "            bestloss = validloss\n",
    "\n",
    "        if epoch[0] > 0:\n",
    "            if validloss < bestloss:\n",
    "                bestloss = validloss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_epoch = epoch[0]\n",
    "                print('new best model saved')\n",
    "                \n",
    "        print('epoch {index} done'.format(index=epoch[0]))\n",
    "        \n",
    "    print('finished looping epochs')\n",
    "    print('best valid loss = {}, epoch {}'.format(bestloss, best_epoch))\n",
    "\n",
    "    # load and save the best model\n",
    "    torch.save(best_model, model_path)\n",
    "    print('best model loaded and saved')\n",
    "\n",
    "    # plot training & validation loss vs. epoch\n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(epochs, train_loss_results)\n",
    "    plt.plot(epochs, valid_loss_results)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    fig1.savefig(fig_path)\n",
    "    print('plot saved')\n",
    "    \n",
    "    # plot training & validation loss vs. epoch -- scale 2\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(epochs, train_loss_results)\n",
    "    plt.plot(epochs, valid_loss_results)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0,(bestloss*100))\n",
    "    plt.show()\n",
    "    fig2.savefig('fig2_path')\n",
    "    print('plot saved')\n",
    "    \n",
    "    # create dataframe of epochs, losses\n",
    "    d = {'trainloss':train_loss_results, 'validloss':valid_loss_results}\n",
    "    df = pd.DataFrame(d, index=epochs)\n",
    "    df.to_csv(df_path)\n",
    "    print('dataframe saved')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "run_training(model=model, modelpath=model_path, figpath=fig_path, fig2path = fig2_path, dfpath=df_path, trainset=trainset, \n",
    "      validsize=valid_size, numepochs=n_epochs, batchsize=batch_size, seed=seed)\n",
    "\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
