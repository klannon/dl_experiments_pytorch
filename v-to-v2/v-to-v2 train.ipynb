{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector-to-Vector Network & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'vtov2_dataset.npz'\n",
    "batch_size = 250\n",
    "n_epochs = 500\n",
    "hidden_layers = [(1,50)]\n",
    "valid_size = 2000\n",
    "model_path = 'vtov2_model_1'\n",
    "fig_path = 'vtov2_fig_1.png'\n",
    "fig2_path = 'vtov2_fig_2.png'\n",
    "df_path = 'vtov2_df_1'\n",
    "seed = np.random.randint(low=0, high=1000000, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "npfile = np.load(infile)\n",
    "inputs = npfile['inputs']\n",
    "outputs = npfile['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing inputs, outputs and coverting to tensors\n",
    "inputMeans = inputs[0:int(inputs.shape[0]),:].mean(axis=0)\n",
    "inputStdDevs = inputs[0:int(inputs.shape[0]),:].std(axis=0)\n",
    "inputs = (inputs-inputMeans)/inputStdDevs\n",
    "inputs = torch.from_numpy(inputs).float()\n",
    "\n",
    "outputMeans = outputs[0:int(outputs.shape[0]),:].mean(axis=0)\n",
    "outputStdDevs = outputs[0:int(outputs.shape[0]),:].std(axis=0)\n",
    "outputs = (outputs-outputMeans)/outputStdDevs\n",
    "outputs = torch.from_numpy(outputs).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a TensorDataset for training\n",
    "trainset = torch.utils.data.TensorDataset(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input, output sizes\n",
    "out_size = list(outputs[0].size())[0]\n",
    "in_size = list(inputs[0].size())[0]\n",
    "\n",
    "# number of hidden layers\n",
    "num = len(hidden_layers)\n",
    "\n",
    "# number of nodes in a given hidden layer\n",
    "def nodes(i):\n",
    "    layer = hidden_layers[i]\n",
    "    dim_node = layer[1]\n",
    "    return dim_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = OrderedDict([])\n",
    "\n",
    "network = OrderedDict([('lin1', nn.Linear(in_size, nodes(0))),('relu1', nn.ReLU())]) \n",
    "if num > 1:\n",
    "    for i in range(1, num):\n",
    "        network['lin{index}'.format(index=i+1)] = nn.Linear(nodes(i-1), nodes(i))\n",
    "        network['relu{index}'.format(index=i+1)] = nn.ReLU()\n",
    "network['lin{index}'.format(index=num+1)] = nn.Linear(nodes(num-1), out_size)    \n",
    "\n",
    "model = nn.Sequential(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the training process for one epoch, returns training loss for given epoch\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # put model into train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (inputs, outputs) in enumerate(loader):\n",
    "        inputs_var = inputs\n",
    "        outputs_var = outputs\n",
    "        \n",
    "        # get model output & loss for each given input\n",
    "        model_outputs = model(inputs_var)\n",
    "        loss = criterion(model_outputs, outputs_var)\n",
    "\n",
    "        # record cummulative loss\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "        # gradient, optimizer steps\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return running_train_loss\n",
    "\n",
    "\n",
    "# defines the validation process for one epoch, returns validation loss for given epoch\n",
    "def validate(model, loader, criterion):\n",
    "    running_valid_loss = 0.0\n",
    "\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (inputs, outputs) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            inputs_var = inputs\n",
    "            outputs_var = outputs\n",
    "\n",
    "            # get model output & loss for each given input\n",
    "            model_outputs = model(inputs_var)\n",
    "            loss = criterion(model_outputs, outputs_var)\n",
    "\n",
    "        # record cummulative loss\n",
    "        running_valid_loss += loss.item()\n",
    "\n",
    "    return running_valid_loss\n",
    "\n",
    "\n",
    "# runs training and validation process over all epochs, returns results\n",
    "def run_training(model, modelpath, figpath, fig2path, dfpath, trainset, validsize, numepochs, batchsize, seed):\n",
    "    # set seed\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # create validation split\n",
    "    indices = torch.randperm(len(trainset))\n",
    "    train_indices = indices[:len(indices) - valid_size]\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "    valid_indices = indices[len(indices) - valid_size:]\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "    # define data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=valid_sampler)\n",
    "  \n",
    "    # set criterion, optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # store results\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    train_loss_results = []\n",
    "    valid_loss_results = []\n",
    "    epochs = []\n",
    "    \n",
    "    # train model\n",
    "    for epoch in enumerate(range(n_epochs)):\n",
    "        trainloss = train(model=model,loader=train_loader,criterion=criterion,optimizer=optimizer)\n",
    "        print('train loss for epoch {index} attained: {loss}'.format(index=epoch[0], loss=trainloss))\n",
    "        \n",
    "        validloss = validate(model=model,loader=valid_loader,criterion=criterion)\n",
    "        print('valid loss for epoch {index} attained: {loss}'.format(index=epoch[0], loss=validloss))\n",
    "        \n",
    "        train_loss_results.append(trainloss)\n",
    "        valid_loss_results.append(validloss)\n",
    "        epochs.append(epoch[0]+1)\n",
    "        \n",
    "        # check if model is the best, save if best\n",
    "        if epoch[0] == 0:\n",
    "            bestloss = validloss\n",
    "\n",
    "        if epoch[0] > 0:\n",
    "            if validloss < bestloss:\n",
    "                bestloss = validloss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_epoch = epoch[0]\n",
    "                print('new best model saved')\n",
    "                \n",
    "        print('epoch {index} done'.format(index=epoch[0]))\n",
    "        \n",
    "    print('finished looping epochs')\n",
    "    print('best valid loss = {}, epoch {}'.format(bestloss, best_epoch))\n",
    "\n",
    "    # load and save the best model\n",
    "    torch.save(best_model, model_path)\n",
    "    print('best model loaded and saved')\n",
    "\n",
    "    # plot training & validation loss vs. epoch\n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(epochs, train_loss_results)\n",
    "    plt.plot(epochs, valid_loss_results)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    fig1.savefig(fig_path)\n",
    "    print('plot saved')\n",
    "    \n",
    "    # plot training & validation loss vs. epoch -- scale 2\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(epochs, train_loss_results)\n",
    "    plt.plot(epochs, valid_loss_results)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0,(bestloss*100))\n",
    "    plt.show()\n",
    "    fig2.savefig('fig2_path')\n",
    "    print('plot saved')\n",
    "    \n",
    "    # create dataframe of epochs, losses\n",
    "    d = {'trainloss':train_loss_results, 'validloss':valid_loss_results}\n",
    "    df = pd.DataFrame(d, index=epochs)\n",
    "    df.to_csv(df_path)\n",
    "    print('dataframe saved')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 0 attained: 23.671279907226562\n",
      "valid loss for epoch 0 attained: 4.431155323982239\n",
      "epoch 0 done\n",
      "train loss for epoch 1 attained: 14.916361004114151\n",
      "valid loss for epoch 1 attained: 3.010825455188751\n",
      "new best model saved\n",
      "epoch 1 done\n",
      "train loss for epoch 2 attained: 11.106350541114807\n",
      "valid loss for epoch 2 attained: 2.43001851439476\n",
      "new best model saved\n",
      "epoch 2 done\n",
      "train loss for epoch 3 attained: 9.370645582675934\n",
      "valid loss for epoch 3 attained: 2.0862362533807755\n",
      "new best model saved\n",
      "epoch 3 done\n",
      "train loss for epoch 4 attained: 8.028527542948723\n",
      "valid loss for epoch 4 attained: 1.7616115659475327\n",
      "new best model saved\n",
      "epoch 4 done\n",
      "train loss for epoch 5 attained: 6.653187811374664\n",
      "valid loss for epoch 5 attained: 1.4233337342739105\n",
      "new best model saved\n",
      "epoch 5 done\n",
      "train loss for epoch 6 attained: 5.251768380403519\n",
      "valid loss for epoch 6 attained: 1.090660348534584\n",
      "new best model saved\n",
      "epoch 6 done\n",
      "train loss for epoch 7 attained: 3.9036694020032883\n",
      "valid loss for epoch 7 attained: 0.7834926545619965\n",
      "new best model saved\n",
      "epoch 7 done\n",
      "train loss for epoch 8 attained: 2.750941537320614\n",
      "valid loss for epoch 8 attained: 0.5387474969029427\n",
      "new best model saved\n",
      "epoch 8 done\n",
      "train loss for epoch 9 attained: 1.8939883336424828\n",
      "valid loss for epoch 9 attained: 0.37442613020539284\n",
      "new best model saved\n",
      "epoch 9 done\n",
      "train loss for epoch 10 attained: 1.3464967086911201\n",
      "valid loss for epoch 10 attained: 0.2737080380320549\n",
      "new best model saved\n",
      "epoch 10 done\n",
      "train loss for epoch 11 attained: 1.021288337185979\n",
      "valid loss for epoch 11 attained: 0.21709666959941387\n",
      "new best model saved\n",
      "epoch 11 done\n",
      "train loss for epoch 12 attained: 0.8308497481048107\n",
      "valid loss for epoch 12 attained: 0.18364934250712395\n",
      "new best model saved\n",
      "epoch 12 done\n",
      "train loss for epoch 13 attained: 0.7155560422688723\n",
      "valid loss for epoch 13 attained: 0.1611246094107628\n",
      "new best model saved\n",
      "epoch 13 done\n",
      "train loss for epoch 14 attained: 0.6355657670646906\n",
      "valid loss for epoch 14 attained: 0.14457422215491533\n",
      "new best model saved\n",
      "epoch 14 done\n",
      "train loss for epoch 15 attained: 0.5755994338542223\n",
      "valid loss for epoch 15 attained: 0.13170725665986538\n",
      "new best model saved\n",
      "epoch 15 done\n",
      "train loss for epoch 16 attained: 0.5247940449044108\n",
      "valid loss for epoch 16 attained: 0.12029927968978882\n",
      "new best model saved\n",
      "epoch 16 done\n",
      "train loss for epoch 17 attained: 0.4829571330919862\n",
      "valid loss for epoch 17 attained: 0.11154911760240793\n",
      "new best model saved\n",
      "epoch 17 done\n",
      "train loss for epoch 18 attained: 0.4470837628468871\n",
      "valid loss for epoch 18 attained: 0.10334055498242378\n",
      "new best model saved\n",
      "epoch 18 done\n",
      "train loss for epoch 19 attained: 0.41555707808583975\n",
      "valid loss for epoch 19 attained: 0.09714408591389656\n",
      "new best model saved\n",
      "epoch 19 done\n",
      "train loss for epoch 20 attained: 0.38794790487736464\n",
      "valid loss for epoch 20 attained: 0.09046876057982445\n",
      "new best model saved\n",
      "epoch 20 done\n",
      "train loss for epoch 21 attained: 0.3636111905798316\n",
      "valid loss for epoch 21 attained: 0.08509872294962406\n",
      "new best model saved\n",
      "epoch 21 done\n",
      "train loss for epoch 22 attained: 0.34227439388632774\n",
      "valid loss for epoch 22 attained: 0.08040601201355457\n",
      "new best model saved\n",
      "epoch 22 done\n",
      "train loss for epoch 23 attained: 0.32267200481146574\n",
      "valid loss for epoch 23 attained: 0.07586217578500509\n",
      "new best model saved\n",
      "epoch 23 done\n",
      "train loss for epoch 24 attained: 0.3054614351131022\n",
      "valid loss for epoch 24 attained: 0.0719864796847105\n",
      "new best model saved\n",
      "epoch 24 done\n",
      "train loss for epoch 25 attained: 0.28939127875491977\n",
      "valid loss for epoch 25 attained: 0.06827625539153814\n",
      "new best model saved\n",
      "epoch 25 done\n",
      "train loss for epoch 26 attained: 0.2747755949385464\n",
      "valid loss for epoch 26 attained: 0.06506213219836354\n",
      "new best model saved\n",
      "epoch 26 done\n",
      "train loss for epoch 27 attained: 0.2606170130893588\n",
      "valid loss for epoch 27 attained: 0.061559880152344704\n",
      "new best model saved\n",
      "epoch 27 done\n",
      "train loss for epoch 28 attained: 0.24738580314442515\n",
      "valid loss for epoch 28 attained: 0.05853289179503918\n",
      "new best model saved\n",
      "epoch 28 done\n",
      "train loss for epoch 29 attained: 0.23498717742040753\n",
      "valid loss for epoch 29 attained: 0.05534122372046113\n",
      "new best model saved\n",
      "epoch 29 done\n",
      "train loss for epoch 30 attained: 0.2223303858190775\n",
      "valid loss for epoch 30 attained: 0.05275180051103234\n",
      "new best model saved\n",
      "epoch 30 done\n",
      "train loss for epoch 31 attained: 0.2102274396456778\n",
      "valid loss for epoch 31 attained: 0.050126593094319105\n",
      "new best model saved\n",
      "epoch 31 done\n",
      "train loss for epoch 32 attained: 0.19875683030113578\n",
      "valid loss for epoch 32 attained: 0.0472733061760664\n",
      "new best model saved\n",
      "epoch 32 done\n",
      "train loss for epoch 33 attained: 0.1878464799374342\n",
      "valid loss for epoch 33 attained: 0.044738374184817076\n",
      "new best model saved\n",
      "epoch 33 done\n",
      "train loss for epoch 34 attained: 0.17771496810019016\n",
      "valid loss for epoch 34 attained: 0.04221823485568166\n",
      "new best model saved\n",
      "epoch 34 done\n",
      "train loss for epoch 35 attained: 0.16843337006866932\n",
      "valid loss for epoch 35 attained: 0.04012892488390207\n",
      "new best model saved\n",
      "epoch 35 done\n",
      "train loss for epoch 36 attained: 0.1593538192100823\n",
      "valid loss for epoch 36 attained: 0.03835738776251674\n",
      "new best model saved\n",
      "epoch 36 done\n",
      "train loss for epoch 37 attained: 0.15112005220726132\n",
      "valid loss for epoch 37 attained: 0.03605093667283654\n",
      "new best model saved\n",
      "epoch 37 done\n",
      "train loss for epoch 38 attained: 0.14327509189024568\n",
      "valid loss for epoch 38 attained: 0.03449190501123667\n",
      "new best model saved\n",
      "epoch 38 done\n",
      "train loss for epoch 39 attained: 0.1358783368486911\n",
      "valid loss for epoch 39 attained: 0.0327852142509073\n",
      "new best model saved\n",
      "epoch 39 done\n",
      "train loss for epoch 40 attained: 0.1293555609881878\n",
      "valid loss for epoch 40 attained: 0.031077908584848046\n",
      "new best model saved\n",
      "epoch 40 done\n",
      "train loss for epoch 41 attained: 0.12325642025098205\n",
      "valid loss for epoch 41 attained: 0.029906962299719453\n",
      "new best model saved\n",
      "epoch 41 done\n",
      "train loss for epoch 42 attained: 0.1175356269814074\n",
      "valid loss for epoch 42 attained: 0.02842495939694345\n",
      "new best model saved\n",
      "epoch 42 done\n",
      "train loss for epoch 43 attained: 0.11239289189688861\n",
      "valid loss for epoch 43 attained: 0.027354261372238398\n",
      "new best model saved\n",
      "epoch 43 done\n",
      "train loss for epoch 44 attained: 0.10763110243715346\n",
      "valid loss for epoch 44 attained: 0.026103586656972766\n",
      "new best model saved\n",
      "epoch 44 done\n",
      "train loss for epoch 45 attained: 0.1031282979529351\n",
      "valid loss for epoch 45 attained: 0.02501532225869596\n",
      "new best model saved\n",
      "epoch 45 done\n",
      "train loss for epoch 46 attained: 0.09879925474524498\n",
      "valid loss for epoch 46 attained: 0.024136916268616915\n",
      "new best model saved\n",
      "epoch 46 done\n",
      "train loss for epoch 47 attained: 0.09504376398399472\n",
      "valid loss for epoch 47 attained: 0.0229642977938056\n",
      "new best model saved\n",
      "epoch 47 done\n",
      "train loss for epoch 48 attained: 0.09121048357337713\n",
      "valid loss for epoch 48 attained: 0.022123239235952497\n",
      "new best model saved\n",
      "epoch 48 done\n",
      "train loss for epoch 49 attained: 0.08748114900663495\n",
      "valid loss for epoch 49 attained: 0.021288263145834208\n",
      "new best model saved\n",
      "epoch 49 done\n",
      "train loss for epoch 50 attained: 0.08407269627787173\n",
      "valid loss for epoch 50 attained: 0.020549706649035215\n",
      "new best model saved\n",
      "epoch 50 done\n",
      "train loss for epoch 51 attained: 0.0808729943819344\n",
      "valid loss for epoch 51 attained: 0.019853738602250814\n",
      "new best model saved\n",
      "epoch 51 done\n",
      "train loss for epoch 52 attained: 0.07792122103273869\n",
      "valid loss for epoch 52 attained: 0.01917911763302982\n",
      "new best model saved\n",
      "epoch 52 done\n",
      "train loss for epoch 53 attained: 0.07507465966045856\n",
      "valid loss for epoch 53 attained: 0.018383207730948925\n",
      "new best model saved\n",
      "epoch 53 done\n",
      "train loss for epoch 54 attained: 0.07231218717060983\n",
      "valid loss for epoch 54 attained: 0.017754794098436832\n",
      "new best model saved\n",
      "epoch 54 done\n",
      "train loss for epoch 55 attained: 0.07010688306763768\n",
      "valid loss for epoch 55 attained: 0.01718650688417256\n",
      "new best model saved\n",
      "epoch 55 done\n",
      "train loss for epoch 56 attained: 0.06740898417774588\n",
      "valid loss for epoch 56 attained: 0.016651450423523784\n",
      "new best model saved\n",
      "epoch 56 done\n",
      "train loss for epoch 57 attained: 0.06507267407141626\n",
      "valid loss for epoch 57 attained: 0.016026028781197965\n",
      "new best model saved\n",
      "epoch 57 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 58 attained: 0.06289150414522737\n",
      "valid loss for epoch 58 attained: 0.01554007176309824\n",
      "new best model saved\n",
      "epoch 58 done\n",
      "train loss for epoch 59 attained: 0.06075188843533397\n",
      "valid loss for epoch 59 attained: 0.015023001935333014\n",
      "new best model saved\n",
      "epoch 59 done\n",
      "train loss for epoch 60 attained: 0.05862009769771248\n",
      "valid loss for epoch 60 attained: 0.014563119621016085\n",
      "new best model saved\n",
      "epoch 60 done\n",
      "train loss for epoch 61 attained: 0.05685670825187117\n",
      "valid loss for epoch 61 attained: 0.014108829782344401\n",
      "new best model saved\n",
      "epoch 61 done\n",
      "train loss for epoch 62 attained: 0.055375245749019086\n",
      "valid loss for epoch 62 attained: 0.013805265305563807\n",
      "new best model saved\n",
      "epoch 62 done\n",
      "train loss for epoch 63 attained: 0.053541593602858484\n",
      "valid loss for epoch 63 attained: 0.01330019417218864\n",
      "new best model saved\n",
      "epoch 63 done\n",
      "train loss for epoch 64 attained: 0.051834813435561955\n",
      "valid loss for epoch 64 attained: 0.012888049124740064\n",
      "new best model saved\n",
      "epoch 64 done\n",
      "train loss for epoch 65 attained: 0.05033843102864921\n",
      "valid loss for epoch 65 attained: 0.012560423463582993\n",
      "new best model saved\n",
      "epoch 65 done\n",
      "train loss for epoch 66 attained: 0.04910083464346826\n",
      "valid loss for epoch 66 attained: 0.01224571792408824\n",
      "new best model saved\n",
      "epoch 66 done\n",
      "train loss for epoch 67 attained: 0.04798645945265889\n",
      "valid loss for epoch 67 attained: 0.011882745078764856\n",
      "new best model saved\n",
      "epoch 67 done\n",
      "train loss for epoch 68 attained: 0.04642436734866351\n",
      "valid loss for epoch 68 attained: 0.011611421825364232\n",
      "new best model saved\n",
      "epoch 68 done\n",
      "train loss for epoch 69 attained: 0.045136246480979025\n",
      "valid loss for epoch 69 attained: 0.011276151635684073\n",
      "new best model saved\n",
      "epoch 69 done\n",
      "train loss for epoch 70 attained: 0.04407419345807284\n",
      "valid loss for epoch 70 attained: 0.01099789934232831\n",
      "new best model saved\n",
      "epoch 70 done\n",
      "train loss for epoch 71 attained: 0.042867112322710454\n",
      "valid loss for epoch 71 attained: 0.010744656203314662\n",
      "new best model saved\n",
      "epoch 71 done\n",
      "train loss for epoch 72 attained: 0.041794388089329004\n",
      "valid loss for epoch 72 attained: 0.010479157674126327\n",
      "new best model saved\n",
      "epoch 72 done\n",
      "train loss for epoch 73 attained: 0.04092338099144399\n",
      "valid loss for epoch 73 attained: 0.010250218794681132\n",
      "new best model saved\n",
      "epoch 73 done\n",
      "train loss for epoch 74 attained: 0.03975614893715829\n",
      "valid loss for epoch 74 attained: 0.009981473558582366\n",
      "new best model saved\n",
      "epoch 74 done\n",
      "train loss for epoch 75 attained: 0.0388582160230726\n",
      "valid loss for epoch 75 attained: 0.009825764456763864\n",
      "new best model saved\n",
      "epoch 75 done\n",
      "train loss for epoch 76 attained: 0.03806054044980556\n",
      "valid loss for epoch 76 attained: 0.009537672740407288\n",
      "new best model saved\n",
      "epoch 76 done\n",
      "train loss for epoch 77 attained: 0.037177570280618966\n",
      "valid loss for epoch 77 attained: 0.009381466079503298\n",
      "new best model saved\n",
      "epoch 77 done\n",
      "train loss for epoch 78 attained: 0.03630336077185348\n",
      "valid loss for epoch 78 attained: 0.009157099877484143\n",
      "new best model saved\n",
      "epoch 78 done\n",
      "train loss for epoch 79 attained: 0.035524878301657736\n",
      "valid loss for epoch 79 attained: 0.008935646852478385\n",
      "new best model saved\n",
      "epoch 79 done\n",
      "train loss for epoch 80 attained: 0.03471611364511773\n",
      "valid loss for epoch 80 attained: 0.008734481409192085\n",
      "new best model saved\n",
      "epoch 80 done\n",
      "train loss for epoch 81 attained: 0.033916764019522816\n",
      "valid loss for epoch 81 attained: 0.008580329827964306\n",
      "new best model saved\n",
      "epoch 81 done\n",
      "train loss for epoch 82 attained: 0.0331935795256868\n",
      "valid loss for epoch 82 attained: 0.0083376927068457\n",
      "new best model saved\n",
      "epoch 82 done\n",
      "train loss for epoch 83 attained: 0.03256935975514352\n",
      "valid loss for epoch 83 attained: 0.008171912690158933\n",
      "new best model saved\n",
      "epoch 83 done\n",
      "train loss for epoch 84 attained: 0.03178947255946696\n",
      "valid loss for epoch 84 attained: 0.007963354815728962\n",
      "new best model saved\n",
      "epoch 84 done\n",
      "train loss for epoch 85 attained: 0.03121503337752074\n",
      "valid loss for epoch 85 attained: 0.007835267402697355\n",
      "new best model saved\n",
      "epoch 85 done\n",
      "train loss for epoch 86 attained: 0.0305312821874395\n",
      "valid loss for epoch 86 attained: 0.00771936058299616\n",
      "new best model saved\n",
      "epoch 86 done\n",
      "train loss for epoch 87 attained: 0.029923356138169765\n",
      "valid loss for epoch 87 attained: 0.007477299135643989\n",
      "new best model saved\n",
      "epoch 87 done\n",
      "train loss for epoch 88 attained: 0.029385677771642804\n",
      "valid loss for epoch 88 attained: 0.007332920213229954\n",
      "new best model saved\n",
      "epoch 88 done\n",
      "train loss for epoch 89 attained: 0.028651008964516222\n",
      "valid loss for epoch 89 attained: 0.007196426333393902\n",
      "new best model saved\n",
      "epoch 89 done\n",
      "train loss for epoch 90 attained: 0.02811419707722962\n",
      "valid loss for epoch 90 attained: 0.007035281043499708\n",
      "new best model saved\n",
      "epoch 90 done\n",
      "train loss for epoch 91 attained: 0.02765185758471489\n",
      "valid loss for epoch 91 attained: 0.006883489317260683\n",
      "new best model saved\n",
      "epoch 91 done\n",
      "train loss for epoch 92 attained: 0.02707463555270806\n",
      "valid loss for epoch 92 attained: 0.006723691010847688\n",
      "new best model saved\n",
      "epoch 92 done\n",
      "train loss for epoch 93 attained: 0.026507513772230595\n",
      "valid loss for epoch 93 attained: 0.006608348921872675\n",
      "new best model saved\n",
      "epoch 93 done\n",
      "train loss for epoch 94 attained: 0.025911597185768187\n",
      "valid loss for epoch 94 attained: 0.006492965971119702\n",
      "new best model saved\n",
      "epoch 94 done\n",
      "train loss for epoch 95 attained: 0.02553908823756501\n",
      "valid loss for epoch 95 attained: 0.006327770417556167\n",
      "new best model saved\n",
      "epoch 95 done\n",
      "train loss for epoch 96 attained: 0.02499624784104526\n",
      "valid loss for epoch 96 attained: 0.006167800282128155\n",
      "new best model saved\n",
      "epoch 96 done\n",
      "train loss for epoch 97 attained: 0.02459029055899009\n",
      "valid loss for epoch 97 attained: 0.006087709567509592\n",
      "new best model saved\n",
      "epoch 97 done\n",
      "train loss for epoch 98 attained: 0.023992338101379573\n",
      "valid loss for epoch 98 attained: 0.005941015260759741\n",
      "new best model saved\n",
      "epoch 98 done\n",
      "train loss for epoch 99 attained: 0.023577912710607052\n",
      "valid loss for epoch 99 attained: 0.005926321435254067\n",
      "new best model saved\n",
      "epoch 99 done\n",
      "train loss for epoch 100 attained: 0.023077863093931228\n",
      "valid loss for epoch 100 attained: 0.005693666520528495\n",
      "new best model saved\n",
      "epoch 100 done\n",
      "train loss for epoch 101 attained: 0.022578117495868355\n",
      "valid loss for epoch 101 attained: 0.005611033528111875\n",
      "new best model saved\n",
      "epoch 101 done\n",
      "train loss for epoch 102 attained: 0.022171835822518915\n",
      "valid loss for epoch 102 attained: 0.005493555159773678\n",
      "new best model saved\n",
      "epoch 102 done\n",
      "train loss for epoch 103 attained: 0.021672639239113778\n",
      "valid loss for epoch 103 attained: 0.0053293907549232244\n",
      "new best model saved\n",
      "epoch 103 done\n",
      "train loss for epoch 104 attained: 0.02123049844522029\n",
      "valid loss for epoch 104 attained: 0.005242389743216336\n",
      "new best model saved\n",
      "epoch 104 done\n",
      "train loss for epoch 105 attained: 0.02089051529765129\n",
      "valid loss for epoch 105 attained: 0.005124261660967022\n",
      "new best model saved\n",
      "epoch 105 done\n",
      "train loss for epoch 106 attained: 0.020356604945845902\n",
      "valid loss for epoch 106 attained: 0.005020198121201247\n",
      "new best model saved\n",
      "epoch 106 done\n",
      "train loss for epoch 107 attained: 0.01987742428900674\n",
      "valid loss for epoch 107 attained: 0.004908217582851648\n",
      "new best model saved\n",
      "epoch 107 done\n",
      "train loss for epoch 108 attained: 0.01949995703762397\n",
      "valid loss for epoch 108 attained: 0.004791013605426997\n",
      "new best model saved\n",
      "epoch 108 done\n",
      "train loss for epoch 109 attained: 0.019056060526054353\n",
      "valid loss for epoch 109 attained: 0.004654864373151213\n",
      "new best model saved\n",
      "epoch 109 done\n",
      "train loss for epoch 110 attained: 0.018432468466926366\n",
      "valid loss for epoch 110 attained: 0.004502903844695538\n",
      "new best model saved\n",
      "epoch 110 done\n",
      "train loss for epoch 111 attained: 0.018042546435026452\n",
      "valid loss for epoch 111 attained: 0.004419271310325712\n",
      "new best model saved\n",
      "epoch 111 done\n",
      "train loss for epoch 112 attained: 0.017416169168427587\n",
      "valid loss for epoch 112 attained: 0.004269237571861595\n",
      "new best model saved\n",
      "epoch 112 done\n",
      "train loss for epoch 113 attained: 0.016920071269851178\n",
      "valid loss for epoch 113 attained: 0.004178640141617507\n",
      "new best model saved\n",
      "epoch 113 done\n",
      "train loss for epoch 114 attained: 0.01650641512242146\n",
      "valid loss for epoch 114 attained: 0.004026220150990412\n",
      "new best model saved\n",
      "epoch 114 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 115 attained: 0.01603444089414552\n",
      "valid loss for epoch 115 attained: 0.003965028910897672\n",
      "new best model saved\n",
      "epoch 115 done\n",
      "train loss for epoch 116 attained: 0.015559855819446966\n",
      "valid loss for epoch 116 attained: 0.003793681418756023\n",
      "new best model saved\n",
      "epoch 116 done\n",
      "train loss for epoch 117 attained: 0.01503031060565263\n",
      "valid loss for epoch 117 attained: 0.003678686131024733\n",
      "new best model saved\n",
      "epoch 117 done\n",
      "train loss for epoch 118 attained: 0.014694691897602752\n",
      "valid loss for epoch 118 attained: 0.003626818535849452\n",
      "new best model saved\n",
      "epoch 118 done\n",
      "train loss for epoch 119 attained: 0.014401042164536193\n",
      "valid loss for epoch 119 attained: 0.003534563584253192\n",
      "new best model saved\n",
      "epoch 119 done\n",
      "train loss for epoch 120 attained: 0.013938774151029065\n",
      "valid loss for epoch 120 attained: 0.003449526207987219\n",
      "new best model saved\n",
      "epoch 120 done\n",
      "train loss for epoch 121 attained: 0.013655857124831527\n",
      "valid loss for epoch 121 attained: 0.003369336191099137\n",
      "new best model saved\n",
      "epoch 121 done\n",
      "train loss for epoch 122 attained: 0.013304578460520133\n",
      "valid loss for epoch 122 attained: 0.003288965002866462\n",
      "new best model saved\n",
      "epoch 122 done\n",
      "train loss for epoch 123 attained: 0.0130677605047822\n",
      "valid loss for epoch 123 attained: 0.0032530523312743753\n",
      "new best model saved\n",
      "epoch 123 done\n",
      "train loss for epoch 124 attained: 0.012959333864273503\n",
      "valid loss for epoch 124 attained: 0.0031849440711084753\n",
      "new best model saved\n",
      "epoch 124 done\n",
      "train loss for epoch 125 attained: 0.012625647912500426\n",
      "valid loss for epoch 125 attained: 0.003147012204863131\n",
      "new best model saved\n",
      "epoch 125 done\n",
      "train loss for epoch 126 attained: 0.012425081135006621\n",
      "valid loss for epoch 126 attained: 0.003082125127548352\n",
      "new best model saved\n",
      "epoch 126 done\n",
      "train loss for epoch 127 attained: 0.012171502225100994\n",
      "valid loss for epoch 127 attained: 0.0031058143940754235\n",
      "epoch 127 done\n",
      "train loss for epoch 128 attained: 0.01195113328867592\n",
      "valid loss for epoch 128 attained: 0.002974023373099044\n",
      "new best model saved\n",
      "epoch 128 done\n",
      "train loss for epoch 129 attained: 0.01192534962319769\n",
      "valid loss for epoch 129 attained: 0.0029475017508957535\n",
      "new best model saved\n",
      "epoch 129 done\n",
      "train loss for epoch 130 attained: 0.011605258740019053\n",
      "valid loss for epoch 130 attained: 0.00286183541174978\n",
      "new best model saved\n",
      "epoch 130 done\n",
      "train loss for epoch 131 attained: 0.011372841021511704\n",
      "valid loss for epoch 131 attained: 0.0028360836149659008\n",
      "new best model saved\n",
      "epoch 131 done\n",
      "train loss for epoch 132 attained: 0.011254435376031324\n",
      "valid loss for epoch 132 attained: 0.002792228857288137\n",
      "new best model saved\n",
      "epoch 132 done\n",
      "train loss for epoch 133 attained: 0.01108656288124621\n",
      "valid loss for epoch 133 attained: 0.0027633399004116654\n",
      "new best model saved\n",
      "epoch 133 done\n",
      "train loss for epoch 134 attained: 0.010904993658186868\n",
      "valid loss for epoch 134 attained: 0.002726564707700163\n",
      "new best model saved\n",
      "epoch 134 done\n",
      "train loss for epoch 135 attained: 0.010741275240434334\n",
      "valid loss for epoch 135 attained: 0.0026640895230229944\n",
      "new best model saved\n",
      "epoch 135 done\n",
      "train loss for epoch 136 attained: 0.010585293202893808\n",
      "valid loss for epoch 136 attained: 0.002641108731040731\n",
      "new best model saved\n",
      "epoch 136 done\n",
      "train loss for epoch 137 attained: 0.0103957666142378\n",
      "valid loss for epoch 137 attained: 0.0025871917023323476\n",
      "new best model saved\n",
      "epoch 137 done\n",
      "train loss for epoch 138 attained: 0.010305841657100245\n",
      "valid loss for epoch 138 attained: 0.0026049618027172983\n",
      "epoch 138 done\n",
      "train loss for epoch 139 attained: 0.010225605830783024\n",
      "valid loss for epoch 139 attained: 0.002602613327326253\n",
      "epoch 139 done\n",
      "train loss for epoch 140 attained: 0.01005892557441257\n",
      "valid loss for epoch 140 attained: 0.002508183504687622\n",
      "new best model saved\n",
      "epoch 140 done\n",
      "train loss for epoch 141 attained: 0.009867796004982665\n",
      "valid loss for epoch 141 attained: 0.002484025724697858\n",
      "new best model saved\n",
      "epoch 141 done\n",
      "train loss for epoch 142 attained: 0.009733699378557503\n",
      "valid loss for epoch 142 attained: 0.0023891759337857366\n",
      "new best model saved\n",
      "epoch 142 done\n",
      "train loss for epoch 143 attained: 0.009542018582578748\n",
      "valid loss for epoch 143 attained: 0.0023683634062763304\n",
      "new best model saved\n",
      "epoch 143 done\n",
      "train loss for epoch 144 attained: 0.009412250685272738\n",
      "valid loss for epoch 144 attained: 0.002341648214496672\n",
      "new best model saved\n",
      "epoch 144 done\n",
      "train loss for epoch 145 attained: 0.009289720474043861\n",
      "valid loss for epoch 145 attained: 0.002302233362570405\n",
      "new best model saved\n",
      "epoch 145 done\n",
      "train loss for epoch 146 attained: 0.009179145097732544\n",
      "valid loss for epoch 146 attained: 0.00230453148833476\n",
      "epoch 146 done\n",
      "train loss for epoch 147 attained: 0.009034125512698665\n",
      "valid loss for epoch 147 attained: 0.0022591754677705467\n",
      "new best model saved\n",
      "epoch 147 done\n",
      "train loss for epoch 148 attained: 0.00893710064701736\n",
      "valid loss for epoch 148 attained: 0.0022041625052224845\n",
      "new best model saved\n",
      "epoch 148 done\n",
      "train loss for epoch 149 attained: 0.00880804487678688\n",
      "valid loss for epoch 149 attained: 0.00220901207649149\n",
      "epoch 149 done\n",
      "train loss for epoch 150 attained: 0.008694943477166817\n",
      "valid loss for epoch 150 attained: 0.002200613613240421\n",
      "new best model saved\n",
      "epoch 150 done\n",
      "train loss for epoch 151 attained: 0.008599373089964502\n",
      "valid loss for epoch 151 attained: 0.002136223381967284\n",
      "new best model saved\n",
      "epoch 151 done\n",
      "train loss for epoch 152 attained: 0.008513203225447796\n",
      "valid loss for epoch 152 attained: 0.002116788236889988\n",
      "new best model saved\n",
      "epoch 152 done\n",
      "train loss for epoch 153 attained: 0.008424763145740144\n",
      "valid loss for epoch 153 attained: 0.002075727708870545\n",
      "new best model saved\n",
      "epoch 153 done\n",
      "train loss for epoch 154 attained: 0.00828793270920869\n",
      "valid loss for epoch 154 attained: 0.0020461586682358757\n",
      "new best model saved\n",
      "epoch 154 done\n",
      "train loss for epoch 155 attained: 0.008247514822869562\n",
      "valid loss for epoch 155 attained: 0.002075472642900422\n",
      "epoch 155 done\n",
      "train loss for epoch 156 attained: 0.00816616827796679\n",
      "valid loss for epoch 156 attained: 0.0020322447235230356\n",
      "new best model saved\n",
      "epoch 156 done\n",
      "train loss for epoch 157 attained: 0.008050443750107661\n",
      "valid loss for epoch 157 attained: 0.001999732747208327\n",
      "new best model saved\n",
      "epoch 157 done\n",
      "train loss for epoch 158 attained: 0.00789508553862106\n",
      "valid loss for epoch 158 attained: 0.0019466430530883372\n",
      "new best model saved\n",
      "epoch 158 done\n",
      "train loss for epoch 159 attained: 0.00785981139051728\n",
      "valid loss for epoch 159 attained: 0.0019659717800095677\n",
      "epoch 159 done\n",
      "train loss for epoch 160 attained: 0.0078031689481576905\n",
      "valid loss for epoch 160 attained: 0.001985214272281155\n",
      "epoch 160 done\n",
      "train loss for epoch 161 attained: 0.007725117247900926\n",
      "valid loss for epoch 161 attained: 0.0019130825385218486\n",
      "new best model saved\n",
      "epoch 161 done\n",
      "train loss for epoch 162 attained: 0.007629994317539968\n",
      "valid loss for epoch 162 attained: 0.001871715154265985\n",
      "new best model saved\n",
      "epoch 162 done\n",
      "train loss for epoch 163 attained: 0.007522510961280204\n",
      "valid loss for epoch 163 attained: 0.0018668067787075415\n",
      "new best model saved\n",
      "epoch 163 done\n",
      "train loss for epoch 164 attained: 0.007455723956809379\n",
      "valid loss for epoch 164 attained: 0.0018508955981815234\n",
      "new best model saved\n",
      "epoch 164 done\n",
      "train loss for epoch 165 attained: 0.0073862769932020456\n",
      "valid loss for epoch 165 attained: 0.0018303902470506728\n",
      "new best model saved\n",
      "epoch 165 done\n",
      "train loss for epoch 166 attained: 0.007361213400145061\n",
      "valid loss for epoch 166 attained: 0.0018998588202521205\n",
      "epoch 166 done\n",
      "train loss for epoch 167 attained: 0.007320288452319801\n",
      "valid loss for epoch 167 attained: 0.0017972680507227778\n",
      "new best model saved\n",
      "epoch 167 done\n",
      "train loss for epoch 168 attained: 0.0072063601546688005\n",
      "valid loss for epoch 168 attained: 0.001857092182035558\n",
      "epoch 168 done\n",
      "train loss for epoch 169 attained: 0.007226491754408926\n",
      "valid loss for epoch 169 attained: 0.0018080978188663721\n",
      "epoch 169 done\n",
      "train loss for epoch 170 attained: 0.007033007248537615\n",
      "valid loss for epoch 170 attained: 0.0017604184540687129\n",
      "new best model saved\n",
      "epoch 170 done\n",
      "train loss for epoch 171 attained: 0.006988572655245662\n",
      "valid loss for epoch 171 attained: 0.0017490570317022502\n",
      "new best model saved\n",
      "epoch 171 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 172 attained: 0.006951520263100974\n",
      "valid loss for epoch 172 attained: 0.0017195510299643502\n",
      "new best model saved\n",
      "epoch 172 done\n",
      "train loss for epoch 173 attained: 0.006977068886044435\n",
      "valid loss for epoch 173 attained: 0.001731393378577195\n",
      "epoch 173 done\n",
      "train loss for epoch 174 attained: 0.006863330359919928\n",
      "valid loss for epoch 174 attained: 0.001700763066764921\n",
      "new best model saved\n",
      "epoch 174 done\n",
      "train loss for epoch 175 attained: 0.006812610736233182\n",
      "valid loss for epoch 175 attained: 0.0016642567206872627\n",
      "new best model saved\n",
      "epoch 175 done\n",
      "train loss for epoch 176 attained: 0.006715713039739057\n",
      "valid loss for epoch 176 attained: 0.001651549042435363\n",
      "new best model saved\n",
      "epoch 176 done\n",
      "train loss for epoch 177 attained: 0.006712075191899203\n",
      "valid loss for epoch 177 attained: 0.0016696903185220435\n",
      "epoch 177 done\n",
      "train loss for epoch 178 attained: 0.006613638091948815\n",
      "valid loss for epoch 178 attained: 0.001664903771597892\n",
      "epoch 178 done\n",
      "train loss for epoch 179 attained: 0.0066282828483963385\n",
      "valid loss for epoch 179 attained: 0.001645203199586831\n",
      "new best model saved\n",
      "epoch 179 done\n",
      "train loss for epoch 180 attained: 0.00655052496585995\n",
      "valid loss for epoch 180 attained: 0.0015968675870681182\n",
      "new best model saved\n",
      "epoch 180 done\n",
      "train loss for epoch 181 attained: 0.006413736191461794\n",
      "valid loss for epoch 181 attained: 0.001612346328329295\n",
      "epoch 181 done\n",
      "train loss for epoch 182 attained: 0.0064480709115741774\n",
      "valid loss for epoch 182 attained: 0.0015814547368790954\n",
      "new best model saved\n",
      "epoch 182 done\n",
      "train loss for epoch 183 attained: 0.006384396081557497\n",
      "valid loss for epoch 183 attained: 0.001621718009118922\n",
      "epoch 183 done\n",
      "train loss for epoch 184 attained: 0.006374601027346216\n",
      "valid loss for epoch 184 attained: 0.0015747776051284745\n",
      "new best model saved\n",
      "epoch 184 done\n",
      "train loss for epoch 185 attained: 0.00628421337751206\n",
      "valid loss for epoch 185 attained: 0.0015388135507237166\n",
      "new best model saved\n",
      "epoch 185 done\n",
      "train loss for epoch 186 attained: 0.006179155549034476\n",
      "valid loss for epoch 186 attained: 0.0015567683731205761\n",
      "epoch 186 done\n",
      "train loss for epoch 187 attained: 0.006235265071154572\n",
      "valid loss for epoch 187 attained: 0.0015388000902021304\n",
      "new best model saved\n",
      "epoch 187 done\n",
      "train loss for epoch 188 attained: 0.006187401158967987\n",
      "valid loss for epoch 188 attained: 0.0015411012718686834\n",
      "epoch 188 done\n",
      "train loss for epoch 189 attained: 0.006097235163906589\n",
      "valid loss for epoch 189 attained: 0.0015020906284917146\n",
      "new best model saved\n",
      "epoch 189 done\n",
      "train loss for epoch 190 attained: 0.006048239971278235\n",
      "valid loss for epoch 190 attained: 0.0015276648773578927\n",
      "epoch 190 done\n",
      "train loss for epoch 191 attained: 0.006007954230881296\n",
      "valid loss for epoch 191 attained: 0.0014829277206445113\n",
      "new best model saved\n",
      "epoch 191 done\n",
      "train loss for epoch 192 attained: 0.005924256227444857\n",
      "valid loss for epoch 192 attained: 0.0014908376469975337\n",
      "epoch 192 done\n",
      "train loss for epoch 193 attained: 0.0059366787754697725\n",
      "valid loss for epoch 193 attained: 0.0015154390130192041\n",
      "epoch 193 done\n",
      "train loss for epoch 194 attained: 0.005867746309377253\n",
      "valid loss for epoch 194 attained: 0.0015083099424373358\n",
      "epoch 194 done\n",
      "train loss for epoch 195 attained: 0.00580994704796467\n",
      "valid loss for epoch 195 attained: 0.0014552542561432347\n",
      "new best model saved\n",
      "epoch 195 done\n",
      "train loss for epoch 196 attained: 0.005804799875477329\n",
      "valid loss for epoch 196 attained: 0.0014326688833534718\n",
      "new best model saved\n",
      "epoch 196 done\n",
      "train loss for epoch 197 attained: 0.005715589053579606\n",
      "valid loss for epoch 197 attained: 0.0014357703039422631\n",
      "epoch 197 done\n",
      "train loss for epoch 198 attained: 0.005675508044078015\n",
      "valid loss for epoch 198 attained: 0.0014179405116010457\n",
      "new best model saved\n",
      "epoch 198 done\n",
      "train loss for epoch 199 attained: 0.0056108862336259335\n",
      "valid loss for epoch 199 attained: 0.001405658244038932\n",
      "new best model saved\n",
      "epoch 199 done\n",
      "train loss for epoch 200 attained: 0.005610266380244866\n",
      "valid loss for epoch 200 attained: 0.0014185991312842816\n",
      "epoch 200 done\n",
      "train loss for epoch 201 attained: 0.005688016128260642\n",
      "valid loss for epoch 201 attained: 0.0014602511218981817\n",
      "epoch 201 done\n",
      "train loss for epoch 202 attained: 0.005605520462268032\n",
      "valid loss for epoch 202 attained: 0.001414446291164495\n",
      "epoch 202 done\n",
      "train loss for epoch 203 attained: 0.005513278287253343\n",
      "valid loss for epoch 203 attained: 0.0013892628630856052\n",
      "new best model saved\n",
      "epoch 203 done\n",
      "train loss for epoch 204 attained: 0.005460890621179715\n",
      "valid loss for epoch 204 attained: 0.0013954015012132004\n",
      "epoch 204 done\n",
      "train loss for epoch 205 attained: 0.005439727421617135\n",
      "valid loss for epoch 205 attained: 0.0014276707370299846\n",
      "epoch 205 done\n",
      "train loss for epoch 206 attained: 0.005441200439236127\n",
      "valid loss for epoch 206 attained: 0.0013324804021976888\n",
      "new best model saved\n",
      "epoch 206 done\n",
      "train loss for epoch 207 attained: 0.005321360193192959\n",
      "valid loss for epoch 207 attained: 0.0013548293500207365\n",
      "epoch 207 done\n",
      "train loss for epoch 208 attained: 0.005294441623846069\n",
      "valid loss for epoch 208 attained: 0.0013174511841498315\n",
      "new best model saved\n",
      "epoch 208 done\n",
      "train loss for epoch 209 attained: 0.005151590346940793\n",
      "valid loss for epoch 209 attained: 0.0013726236065849662\n",
      "epoch 209 done\n",
      "train loss for epoch 210 attained: 0.0051926326705142856\n",
      "valid loss for epoch 210 attained: 0.001313967484747991\n",
      "new best model saved\n",
      "epoch 210 done\n",
      "train loss for epoch 211 attained: 0.0052265411941334605\n",
      "valid loss for epoch 211 attained: 0.0013202147820265964\n",
      "epoch 211 done\n",
      "train loss for epoch 212 attained: 0.00507044984260574\n",
      "valid loss for epoch 212 attained: 0.001292615372221917\n",
      "new best model saved\n",
      "epoch 212 done\n",
      "train loss for epoch 213 attained: 0.005144925249624066\n",
      "valid loss for epoch 213 attained: 0.0012837889953516424\n",
      "new best model saved\n",
      "epoch 213 done\n",
      "train loss for epoch 214 attained: 0.005035676033003256\n",
      "valid loss for epoch 214 attained: 0.0013038892211625353\n",
      "epoch 214 done\n",
      "train loss for epoch 215 attained: 0.004987496256944723\n",
      "valid loss for epoch 215 attained: 0.0012786408478859812\n",
      "new best model saved\n",
      "epoch 215 done\n",
      "train loss for epoch 216 attained: 0.005003910031518899\n",
      "valid loss for epoch 216 attained: 0.0012496265408117324\n",
      "new best model saved\n",
      "epoch 216 done\n",
      "train loss for epoch 217 attained: 0.004936986428219825\n",
      "valid loss for epoch 217 attained: 0.0012546375073725358\n",
      "epoch 217 done\n",
      "train loss for epoch 218 attained: 0.004900375206489116\n",
      "valid loss for epoch 218 attained: 0.001231562317116186\n",
      "new best model saved\n",
      "epoch 218 done\n",
      "train loss for epoch 219 attained: 0.004858384301769547\n",
      "valid loss for epoch 219 attained: 0.001258917196537368\n",
      "epoch 219 done\n",
      "train loss for epoch 220 attained: 0.004936349636409432\n",
      "valid loss for epoch 220 attained: 0.0012609396508196369\n",
      "epoch 220 done\n",
      "train loss for epoch 221 attained: 0.004873223922913894\n",
      "valid loss for epoch 221 attained: 0.0012052376405335963\n",
      "new best model saved\n",
      "epoch 221 done\n",
      "train loss for epoch 222 attained: 0.004780024668434635\n",
      "valid loss for epoch 222 attained: 0.0012256305199116468\n",
      "epoch 222 done\n",
      "train loss for epoch 223 attained: 0.004782043237355538\n",
      "valid loss for epoch 223 attained: 0.0012344353162916377\n",
      "epoch 223 done\n",
      "train loss for epoch 224 attained: 0.004868816118687391\n",
      "valid loss for epoch 224 attained: 0.001227524786372669\n",
      "epoch 224 done\n",
      "train loss for epoch 225 attained: 0.0047560674720443785\n",
      "valid loss for epoch 225 attained: 0.0012191799469292164\n",
      "epoch 225 done\n",
      "train loss for epoch 226 attained: 0.004813190404092893\n",
      "valid loss for epoch 226 attained: 0.0011863188847200945\n",
      "new best model saved\n",
      "epoch 226 done\n",
      "train loss for epoch 227 attained: 0.00467195306555368\n",
      "valid loss for epoch 227 attained: 0.0011576779215829447\n",
      "new best model saved\n",
      "epoch 227 done\n",
      "train loss for epoch 228 attained: 0.004618487000698224\n",
      "valid loss for epoch 228 attained: 0.00115010239824187\n",
      "new best model saved\n",
      "epoch 228 done\n",
      "train loss for epoch 229 attained: 0.004603848181432113\n",
      "valid loss for epoch 229 attained: 0.001210684364195913\n",
      "epoch 229 done\n",
      "train loss for epoch 230 attained: 0.004594197162077762\n",
      "valid loss for epoch 230 attained: 0.001168081711512059\n",
      "epoch 230 done\n",
      "train loss for epoch 231 attained: 0.004585223476169631\n",
      "valid loss for epoch 231 attained: 0.001189221497043036\n",
      "epoch 231 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 232 attained: 0.004545217234408483\n",
      "valid loss for epoch 232 attained: 0.001209955065860413\n",
      "epoch 232 done\n",
      "train loss for epoch 233 attained: 0.004536980115517508\n",
      "valid loss for epoch 233 attained: 0.0011906248546438292\n",
      "epoch 233 done\n",
      "train loss for epoch 234 attained: 0.004450267028005328\n",
      "valid loss for epoch 234 attained: 0.0011440516536822543\n",
      "new best model saved\n",
      "epoch 234 done\n",
      "train loss for epoch 235 attained: 0.00439500995707931\n",
      "valid loss for epoch 235 attained: 0.0011218018917134032\n",
      "new best model saved\n",
      "epoch 235 done\n",
      "train loss for epoch 236 attained: 0.004391515161842108\n",
      "valid loss for epoch 236 attained: 0.0011419141810620204\n",
      "epoch 236 done\n",
      "train loss for epoch 237 attained: 0.004465477846679278\n",
      "valid loss for epoch 237 attained: 0.0011059457901865244\n",
      "new best model saved\n",
      "epoch 237 done\n",
      "train loss for epoch 238 attained: 0.004355256314738654\n",
      "valid loss for epoch 238 attained: 0.0011361699871486053\n",
      "epoch 238 done\n",
      "train loss for epoch 239 attained: 0.004312575416406617\n",
      "valid loss for epoch 239 attained: 0.0011271351831965148\n",
      "epoch 239 done\n",
      "train loss for epoch 240 attained: 0.004358997139206622\n",
      "valid loss for epoch 240 attained: 0.0011265439534327015\n",
      "epoch 240 done\n",
      "train loss for epoch 241 attained: 0.004335457175329793\n",
      "valid loss for epoch 241 attained: 0.0011667458602460101\n",
      "epoch 241 done\n",
      "train loss for epoch 242 attained: 0.004352842268417589\n",
      "valid loss for epoch 242 attained: 0.001089280063752085\n",
      "new best model saved\n",
      "epoch 242 done\n",
      "train loss for epoch 243 attained: 0.004283618982299231\n",
      "valid loss for epoch 243 attained: 0.0011082992277806625\n",
      "epoch 243 done\n",
      "train loss for epoch 244 attained: 0.004291402576200198\n",
      "valid loss for epoch 244 attained: 0.0011060932010877877\n",
      "epoch 244 done\n",
      "train loss for epoch 245 attained: 0.004228033445542678\n",
      "valid loss for epoch 245 attained: 0.0011011656461050734\n",
      "epoch 245 done\n",
      "train loss for epoch 246 attained: 0.004240073933033273\n",
      "valid loss for epoch 246 attained: 0.0011046527361031622\n",
      "epoch 246 done\n",
      "train loss for epoch 247 attained: 0.004175434492935892\n",
      "valid loss for epoch 247 attained: 0.001087715631001629\n",
      "new best model saved\n",
      "epoch 247 done\n",
      "train loss for epoch 248 attained: 0.004146714782109484\n",
      "valid loss for epoch 248 attained: 0.001087751952582039\n",
      "epoch 248 done\n",
      "train loss for epoch 249 attained: 0.004186992395261768\n",
      "valid loss for epoch 249 attained: 0.0010742903396021575\n",
      "new best model saved\n",
      "epoch 249 done\n",
      "train loss for epoch 250 attained: 0.0041065307523240335\n",
      "valid loss for epoch 250 attained: 0.0010937216284219176\n",
      "epoch 250 done\n",
      "train loss for epoch 251 attained: 0.004071767776622437\n",
      "valid loss for epoch 251 attained: 0.001076310218195431\n",
      "epoch 251 done\n",
      "train loss for epoch 252 attained: 0.004138320764468517\n",
      "valid loss for epoch 252 attained: 0.0010851303959498182\n",
      "epoch 252 done\n",
      "train loss for epoch 253 attained: 0.004154594236752018\n",
      "valid loss for epoch 253 attained: 0.0011000129888998345\n",
      "epoch 253 done\n",
      "train loss for epoch 254 attained: 0.0041394087675143965\n",
      "valid loss for epoch 254 attained: 0.0010474974114913493\n",
      "new best model saved\n",
      "epoch 254 done\n",
      "train loss for epoch 255 attained: 0.0040678924560779706\n",
      "valid loss for epoch 255 attained: 0.0010736446783994325\n",
      "epoch 255 done\n",
      "train loss for epoch 256 attained: 0.003991541983850766\n",
      "valid loss for epoch 256 attained: 0.0010633542551659048\n",
      "epoch 256 done\n",
      "train loss for epoch 257 attained: 0.004019856060040183\n",
      "valid loss for epoch 257 attained: 0.0010591624595690519\n",
      "epoch 257 done\n",
      "train loss for epoch 258 attained: 0.004021370979899075\n",
      "valid loss for epoch 258 attained: 0.001051145329256542\n",
      "epoch 258 done\n",
      "train loss for epoch 259 attained: 0.004077122030139435\n",
      "valid loss for epoch 259 attained: 0.001056460794643499\n",
      "epoch 259 done\n",
      "train loss for epoch 260 attained: 0.004031509175547399\n",
      "valid loss for epoch 260 attained: 0.0010307835837011226\n",
      "new best model saved\n",
      "epoch 260 done\n",
      "train loss for epoch 261 attained: 0.003974527258833405\n",
      "valid loss for epoch 261 attained: 0.0010243625511066057\n",
      "new best model saved\n",
      "epoch 261 done\n",
      "train loss for epoch 262 attained: 0.0039665183576289564\n",
      "valid loss for epoch 262 attained: 0.0010147976718144491\n",
      "new best model saved\n",
      "epoch 262 done\n",
      "train loss for epoch 263 attained: 0.003901563832187094\n",
      "valid loss for epoch 263 attained: 0.0010484577214810997\n",
      "epoch 263 done\n",
      "train loss for epoch 264 attained: 0.00389003346208483\n",
      "valid loss for epoch 264 attained: 0.0010038635664386675\n",
      "new best model saved\n",
      "epoch 264 done\n",
      "train loss for epoch 265 attained: 0.0038586587106692605\n",
      "valid loss for epoch 265 attained: 0.0010341097149648704\n",
      "epoch 265 done\n",
      "train loss for epoch 266 attained: 0.003874694426485803\n",
      "valid loss for epoch 266 attained: 0.0010263536678394303\n",
      "epoch 266 done\n",
      "train loss for epoch 267 attained: 0.003884800935338717\n",
      "valid loss for epoch 267 attained: 0.0010186488943872973\n",
      "epoch 267 done\n",
      "train loss for epoch 268 attained: 0.0038535190833499655\n",
      "valid loss for epoch 268 attained: 0.0010327173949917778\n",
      "epoch 268 done\n",
      "train loss for epoch 269 attained: 0.0038447461993200704\n",
      "valid loss for epoch 269 attained: 0.001039342416333966\n",
      "epoch 269 done\n",
      "train loss for epoch 270 attained: 0.0038251676960499026\n",
      "valid loss for epoch 270 attained: 0.0009995402142521925\n",
      "new best model saved\n",
      "epoch 270 done\n",
      "train loss for epoch 271 attained: 0.0038881714499439113\n",
      "valid loss for epoch 271 attained: 0.001007760045467876\n",
      "epoch 271 done\n",
      "train loss for epoch 272 attained: 0.003815455660514999\n",
      "valid loss for epoch 272 attained: 0.0010185500868828967\n",
      "epoch 272 done\n",
      "train loss for epoch 273 attained: 0.003801695565925911\n",
      "valid loss for epoch 273 attained: 0.0009981235052691773\n",
      "new best model saved\n",
      "epoch 273 done\n",
      "train loss for epoch 274 attained: 0.0038030095092835836\n",
      "valid loss for epoch 274 attained: 0.0010792290850076824\n",
      "epoch 274 done\n",
      "train loss for epoch 275 attained: 0.0037743103530374356\n",
      "valid loss for epoch 275 attained: 0.000978708965703845\n",
      "new best model saved\n",
      "epoch 275 done\n",
      "train loss for epoch 276 attained: 0.003811320311797317\n",
      "valid loss for epoch 276 attained: 0.0009884081446216442\n",
      "epoch 276 done\n",
      "train loss for epoch 277 attained: 0.003725010683410801\n",
      "valid loss for epoch 277 attained: 0.0010074780220747925\n",
      "epoch 277 done\n",
      "train loss for epoch 278 attained: 0.003778749429329764\n",
      "valid loss for epoch 278 attained: 0.0010537038251641206\n",
      "epoch 278 done\n",
      "train loss for epoch 279 attained: 0.0037841207667952403\n",
      "valid loss for epoch 279 attained: 0.0010839392198249698\n",
      "epoch 279 done\n",
      "train loss for epoch 280 attained: 0.0038610451520071365\n",
      "valid loss for epoch 280 attained: 0.0010120872102561407\n",
      "epoch 280 done\n",
      "train loss for epoch 281 attained: 0.003709497941599693\n",
      "valid loss for epoch 281 attained: 0.0010015698208007962\n",
      "epoch 281 done\n",
      "train loss for epoch 282 attained: 0.0036863241330138408\n",
      "valid loss for epoch 282 attained: 0.0010010110345319845\n",
      "epoch 282 done\n",
      "train loss for epoch 283 attained: 0.0036671309717348777\n",
      "valid loss for epoch 283 attained: 0.0009894681861624122\n",
      "epoch 283 done\n",
      "train loss for epoch 284 attained: 0.0036951846923329867\n",
      "valid loss for epoch 284 attained: 0.000975112707237713\n",
      "new best model saved\n",
      "epoch 284 done\n",
      "train loss for epoch 285 attained: 0.0037648257057298906\n",
      "valid loss for epoch 285 attained: 0.0009647867700550705\n",
      "new best model saved\n",
      "epoch 285 done\n",
      "train loss for epoch 286 attained: 0.003693983184348326\n",
      "valid loss for epoch 286 attained: 0.000994661902950611\n",
      "epoch 286 done\n",
      "train loss for epoch 287 attained: 0.0036208282690495253\n",
      "valid loss for epoch 287 attained: 0.000949932356888894\n",
      "new best model saved\n",
      "epoch 287 done\n",
      "train loss for epoch 288 attained: 0.003611809035646729\n",
      "valid loss for epoch 288 attained: 0.0009813378565013409\n",
      "epoch 288 done\n",
      "train loss for epoch 289 attained: 0.0036525184696074575\n",
      "valid loss for epoch 289 attained: 0.0010121057712240145\n",
      "epoch 289 done\n",
      "train loss for epoch 290 attained: 0.0036649241810664535\n",
      "valid loss for epoch 290 attained: 0.0010058806219603866\n",
      "epoch 290 done\n",
      "train loss for epoch 291 attained: 0.003629230152000673\n",
      "valid loss for epoch 291 attained: 0.0009863827217486687\n",
      "epoch 291 done\n",
      "train loss for epoch 292 attained: 0.003642199830210302\n",
      "valid loss for epoch 292 attained: 0.0009505970301688649\n",
      "epoch 292 done\n",
      "train loss for epoch 293 attained: 0.003652309183962643\n",
      "valid loss for epoch 293 attained: 0.0009606927560525946\n",
      "epoch 293 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 294 attained: 0.0036812965699937195\n",
      "valid loss for epoch 294 attained: 0.0010097104532178491\n",
      "epoch 294 done\n",
      "train loss for epoch 295 attained: 0.003555608549504541\n",
      "valid loss for epoch 295 attained: 0.0009595413066563196\n",
      "epoch 295 done\n",
      "train loss for epoch 296 attained: 0.003561023790098261\n",
      "valid loss for epoch 296 attained: 0.0009473255122429691\n",
      "new best model saved\n",
      "epoch 296 done\n",
      "train loss for epoch 297 attained: 0.0035997401719214395\n",
      "valid loss for epoch 297 attained: 0.0009408424739376642\n",
      "new best model saved\n",
      "epoch 297 done\n",
      "train loss for epoch 298 attained: 0.003566844512533862\n",
      "valid loss for epoch 298 attained: 0.0010218565730610862\n",
      "epoch 298 done\n",
      "train loss for epoch 299 attained: 0.003630072016676422\n",
      "valid loss for epoch 299 attained: 0.0009526206777081825\n",
      "epoch 299 done\n",
      "train loss for epoch 300 attained: 0.0035921387243433855\n",
      "valid loss for epoch 300 attained: 0.0010224065190413967\n",
      "epoch 300 done\n",
      "train loss for epoch 301 attained: 0.003557479110895656\n",
      "valid loss for epoch 301 attained: 0.000942611564823892\n",
      "epoch 301 done\n",
      "train loss for epoch 302 attained: 0.003539227182045579\n",
      "valid loss for epoch 302 attained: 0.0009341886034235358\n",
      "new best model saved\n",
      "epoch 302 done\n",
      "train loss for epoch 303 attained: 0.0036358004581416026\n",
      "valid loss for epoch 303 attained: 0.000980430115305353\n",
      "epoch 303 done\n",
      "train loss for epoch 304 attained: 0.003646311794000212\n",
      "valid loss for epoch 304 attained: 0.0010118681311723776\n",
      "epoch 304 done\n",
      "train loss for epoch 305 attained: 0.0035615323067759164\n",
      "valid loss for epoch 305 attained: 0.0009868565903161652\n",
      "epoch 305 done\n",
      "train loss for epoch 306 attained: 0.0034632533352123573\n",
      "valid loss for epoch 306 attained: 0.0009224053064826876\n",
      "new best model saved\n",
      "epoch 306 done\n",
      "train loss for epoch 307 attained: 0.003455134865362197\n",
      "valid loss for epoch 307 attained: 0.000937610624532681\n",
      "epoch 307 done\n",
      "train loss for epoch 308 attained: 0.0034735059598460793\n",
      "valid loss for epoch 308 attained: 0.0009354924986837432\n",
      "epoch 308 done\n",
      "train loss for epoch 309 attained: 0.0035718403159989975\n",
      "valid loss for epoch 309 attained: 0.0009368186510982923\n",
      "epoch 309 done\n",
      "train loss for epoch 310 attained: 0.0034374566967017017\n",
      "valid loss for epoch 310 attained: 0.0009116486835409887\n",
      "new best model saved\n",
      "epoch 310 done\n",
      "train loss for epoch 311 attained: 0.003417451480345335\n",
      "valid loss for epoch 311 attained: 0.0009144505165750161\n",
      "epoch 311 done\n",
      "train loss for epoch 312 attained: 0.003428840238484554\n",
      "valid loss for epoch 312 attained: 0.0009096516369027086\n",
      "new best model saved\n",
      "epoch 312 done\n",
      "train loss for epoch 313 attained: 0.0033942892550840043\n",
      "valid loss for epoch 313 attained: 0.000905608176253736\n",
      "new best model saved\n",
      "epoch 313 done\n",
      "train loss for epoch 314 attained: 0.0034759552581817843\n",
      "valid loss for epoch 314 attained: 0.0009328815795015544\n",
      "epoch 314 done\n",
      "train loss for epoch 315 attained: 0.0035346965596545488\n",
      "valid loss for epoch 315 attained: 0.0009318694937974215\n",
      "epoch 315 done\n",
      "train loss for epoch 316 attained: 0.003551871450326871\n",
      "valid loss for epoch 316 attained: 0.0009110556275118142\n",
      "epoch 316 done\n",
      "train loss for epoch 317 attained: 0.0034758540568873286\n",
      "valid loss for epoch 317 attained: 0.000911653543880675\n",
      "epoch 317 done\n",
      "train loss for epoch 318 attained: 0.0033702823784551583\n",
      "valid loss for epoch 318 attained: 0.0009615373346605338\n",
      "epoch 318 done\n",
      "train loss for epoch 319 attained: 0.0034679821837926283\n",
      "valid loss for epoch 319 attained: 0.0009370474217575975\n",
      "epoch 319 done\n",
      "train loss for epoch 320 attained: 0.003462743123236578\n",
      "valid loss for epoch 320 attained: 0.0009162723363260739\n",
      "epoch 320 done\n",
      "train loss for epoch 321 attained: 0.003481072904833127\n",
      "valid loss for epoch 321 attained: 0.0009029296852531843\n",
      "new best model saved\n",
      "epoch 321 done\n",
      "train loss for epoch 322 attained: 0.0034095782320946455\n",
      "valid loss for epoch 322 attained: 0.0009208831179421395\n",
      "epoch 322 done\n",
      "train loss for epoch 323 attained: 0.0034053424751618877\n",
      "valid loss for epoch 323 attained: 0.0009183514484902844\n",
      "epoch 323 done\n",
      "train loss for epoch 324 attained: 0.0034256604631082155\n",
      "valid loss for epoch 324 attained: 0.0009017869815579616\n",
      "new best model saved\n",
      "epoch 324 done\n",
      "train loss for epoch 325 attained: 0.0034220763336634263\n",
      "valid loss for epoch 325 attained: 0.0009107224541367032\n",
      "epoch 325 done\n",
      "train loss for epoch 326 attained: 0.0034226148345624097\n",
      "valid loss for epoch 326 attained: 0.0008905332433641888\n",
      "new best model saved\n",
      "epoch 326 done\n",
      "train loss for epoch 327 attained: 0.003356105968123302\n",
      "valid loss for epoch 327 attained: 0.0008980241764220409\n",
      "epoch 327 done\n",
      "train loss for epoch 328 attained: 0.0033542143282829784\n",
      "valid loss for epoch 328 attained: 0.0008916428196243942\n",
      "epoch 328 done\n",
      "train loss for epoch 329 attained: 0.003380320966243744\n",
      "valid loss for epoch 329 attained: 0.0009335000795545056\n",
      "epoch 329 done\n",
      "train loss for epoch 330 attained: 0.0033365935159963556\n",
      "valid loss for epoch 330 attained: 0.0009120921240537427\n",
      "epoch 330 done\n",
      "train loss for epoch 331 attained: 0.003339769536978565\n",
      "valid loss for epoch 331 attained: 0.0009119535607169382\n",
      "epoch 331 done\n",
      "train loss for epoch 332 attained: 0.0033585537312319502\n",
      "valid loss for epoch 332 attained: 0.0008812538217171095\n",
      "new best model saved\n",
      "epoch 332 done\n",
      "train loss for epoch 333 attained: 0.0033425582296331413\n",
      "valid loss for epoch 333 attained: 0.0009234510798705742\n",
      "epoch 333 done\n",
      "train loss for epoch 334 attained: 0.003363481577252969\n",
      "valid loss for epoch 334 attained: 0.0008821560986689292\n",
      "epoch 334 done\n",
      "train loss for epoch 335 attained: 0.0033480788915767334\n",
      "valid loss for epoch 335 attained: 0.0008870097735780291\n",
      "epoch 335 done\n",
      "train loss for epoch 336 attained: 0.0033245394297409803\n",
      "valid loss for epoch 336 attained: 0.0009332445042673498\n",
      "epoch 336 done\n",
      "train loss for epoch 337 attained: 0.003297042967460584\n",
      "valid loss for epoch 337 attained: 0.0009252130548702553\n",
      "epoch 337 done\n",
      "train loss for epoch 338 attained: 0.0033743692183634266\n",
      "valid loss for epoch 338 attained: 0.0008905250215320848\n",
      "epoch 338 done\n",
      "train loss for epoch 339 attained: 0.0033444336731918156\n",
      "valid loss for epoch 339 attained: 0.0009264964392059483\n",
      "epoch 339 done\n",
      "train loss for epoch 340 attained: 0.0033740282597136684\n",
      "valid loss for epoch 340 attained: 0.0008954353470471688\n",
      "epoch 340 done\n",
      "train loss for epoch 341 attained: 0.0033543121244292706\n",
      "valid loss for epoch 341 attained: 0.0009201056600431912\n",
      "epoch 341 done\n",
      "train loss for epoch 342 attained: 0.0033696064128889702\n",
      "valid loss for epoch 342 attained: 0.0009086946884053759\n",
      "epoch 342 done\n",
      "train loss for epoch 343 attained: 0.003356523135153111\n",
      "valid loss for epoch 343 attained: 0.0008614905964350328\n",
      "new best model saved\n",
      "epoch 343 done\n",
      "train loss for epoch 344 attained: 0.003289967236923985\n",
      "valid loss for epoch 344 attained: 0.0009144063224084675\n",
      "epoch 344 done\n",
      "train loss for epoch 345 attained: 0.003288143147074152\n",
      "valid loss for epoch 345 attained: 0.0008689247333677486\n",
      "epoch 345 done\n",
      "train loss for epoch 346 attained: 0.0033149509617942385\n",
      "valid loss for epoch 346 attained: 0.0008821564260870218\n",
      "epoch 346 done\n",
      "train loss for epoch 347 attained: 0.0033215584990102798\n",
      "valid loss for epoch 347 attained: 0.000905749315279536\n",
      "epoch 347 done\n",
      "train loss for epoch 348 attained: 0.0032914362745941617\n",
      "valid loss for epoch 348 attained: 0.0008918823004933074\n",
      "epoch 348 done\n",
      "train loss for epoch 349 attained: 0.003254235300119035\n",
      "valid loss for epoch 349 attained: 0.0008503304998157546\n",
      "new best model saved\n",
      "epoch 349 done\n",
      "train loss for epoch 350 attained: 0.003259093042288441\n",
      "valid loss for epoch 350 attained: 0.0008967507601482794\n",
      "epoch 350 done\n",
      "train loss for epoch 351 attained: 0.0032658090713084675\n",
      "valid loss for epoch 351 attained: 0.0008828948193695396\n",
      "epoch 351 done\n",
      "train loss for epoch 352 attained: 0.0032584932632744312\n",
      "valid loss for epoch 352 attained: 0.0008814231478027068\n",
      "epoch 352 done\n",
      "train loss for epoch 353 attained: 0.003240496836951934\n",
      "valid loss for epoch 353 attained: 0.0008963569925981574\n",
      "epoch 353 done\n",
      "train loss for epoch 354 attained: 0.003312735956569668\n",
      "valid loss for epoch 354 attained: 0.0008737272655707784\n",
      "epoch 354 done\n",
      "train loss for epoch 355 attained: 0.0033231330671696924\n",
      "valid loss for epoch 355 attained: 0.0008843351242830977\n",
      "epoch 355 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 356 attained: 0.003256773699831683\n",
      "valid loss for epoch 356 attained: 0.0008513498250977136\n",
      "epoch 356 done\n",
      "train loss for epoch 357 attained: 0.003237587006879039\n",
      "valid loss for epoch 357 attained: 0.0008646291316836141\n",
      "epoch 357 done\n",
      "train loss for epoch 358 attained: 0.003210190945537761\n",
      "valid loss for epoch 358 attained: 0.0009079408046090975\n",
      "epoch 358 done\n",
      "train loss for epoch 359 attained: 0.003248231085308362\n",
      "valid loss for epoch 359 attained: 0.0008679790116730146\n",
      "epoch 359 done\n",
      "train loss for epoch 360 attained: 0.0033297059489996172\n",
      "valid loss for epoch 360 attained: 0.0008710695401532575\n",
      "epoch 360 done\n",
      "train loss for epoch 361 attained: 0.003228133740776684\n",
      "valid loss for epoch 361 attained: 0.0008733143622521311\n",
      "epoch 361 done\n",
      "train loss for epoch 362 attained: 0.00325354773667641\n",
      "valid loss for epoch 362 attained: 0.0008623641479061916\n",
      "epoch 362 done\n",
      "train loss for epoch 363 attained: 0.003258238037233241\n",
      "valid loss for epoch 363 attained: 0.0008628736541140825\n",
      "epoch 363 done\n",
      "train loss for epoch 364 attained: 0.003218295307306107\n",
      "valid loss for epoch 364 attained: 0.0008872523103491403\n",
      "epoch 364 done\n",
      "train loss for epoch 365 attained: 0.0032038236313383095\n",
      "valid loss for epoch 365 attained: 0.0008545043529011309\n",
      "epoch 365 done\n",
      "train loss for epoch 366 attained: 0.0032972919652820565\n",
      "valid loss for epoch 366 attained: 0.0008698176316102035\n",
      "epoch 366 done\n",
      "train loss for epoch 367 attained: 0.0032527696166653186\n",
      "valid loss for epoch 367 attained: 0.0008682480329298414\n",
      "epoch 367 done\n",
      "train loss for epoch 368 attained: 0.003197358746547252\n",
      "valid loss for epoch 368 attained: 0.0008898991873138584\n",
      "epoch 368 done\n",
      "train loss for epoch 369 attained: 0.0032016085751820356\n",
      "valid loss for epoch 369 attained: 0.0008967274625319988\n",
      "epoch 369 done\n",
      "train loss for epoch 370 attained: 0.0032236540646408685\n",
      "valid loss for epoch 370 attained: 0.0008736245217733085\n",
      "epoch 370 done\n",
      "train loss for epoch 371 attained: 0.0032225355971604586\n",
      "valid loss for epoch 371 attained: 0.0008304733273689635\n",
      "new best model saved\n",
      "epoch 371 done\n",
      "train loss for epoch 372 attained: 0.003179018611263018\n",
      "valid loss for epoch 372 attained: 0.0008468333253404126\n",
      "epoch 372 done\n",
      "train loss for epoch 373 attained: 0.003165722082485445\n",
      "valid loss for epoch 373 attained: 0.0008570541904191487\n",
      "epoch 373 done\n",
      "train loss for epoch 374 attained: 0.0032721449606469832\n",
      "valid loss for epoch 374 attained: 0.0008789363200776279\n",
      "epoch 374 done\n",
      "train loss for epoch 375 attained: 0.003232882052543573\n",
      "valid loss for epoch 375 attained: 0.0008410245645791292\n",
      "epoch 375 done\n",
      "train loss for epoch 376 attained: 0.0031770076893735677\n",
      "valid loss for epoch 376 attained: 0.000854279613122344\n",
      "epoch 376 done\n",
      "train loss for epoch 377 attained: 0.003151907556457445\n",
      "valid loss for epoch 377 attained: 0.0008612555830040947\n",
      "epoch 377 done\n",
      "train loss for epoch 378 attained: 0.0032603449435555376\n",
      "valid loss for epoch 378 attained: 0.0009227079499396496\n",
      "epoch 378 done\n",
      "train loss for epoch 379 attained: 0.0032085897037177347\n",
      "valid loss for epoch 379 attained: 0.0008423567487625405\n",
      "epoch 379 done\n",
      "train loss for epoch 380 attained: 0.003227942346711643\n",
      "valid loss for epoch 380 attained: 0.0008608737989561632\n",
      "epoch 380 done\n",
      "train loss for epoch 381 attained: 0.0031597832348779775\n",
      "valid loss for epoch 381 attained: 0.0008747664323891513\n",
      "epoch 381 done\n",
      "train loss for epoch 382 attained: 0.0031478788441745564\n",
      "valid loss for epoch 382 attained: 0.0008394016404054128\n",
      "epoch 382 done\n",
      "train loss for epoch 383 attained: 0.0031833649045438506\n",
      "valid loss for epoch 383 attained: 0.000837395891721826\n",
      "epoch 383 done\n",
      "train loss for epoch 384 attained: 0.0032025925611378625\n",
      "valid loss for epoch 384 attained: 0.0009150060504907742\n",
      "epoch 384 done\n",
      "train loss for epoch 385 attained: 0.0032603802537778392\n",
      "valid loss for epoch 385 attained: 0.0008341671418747865\n",
      "epoch 385 done\n",
      "train loss for epoch 386 attained: 0.0031095310987439007\n",
      "valid loss for epoch 386 attained: 0.0008336491300724447\n",
      "epoch 386 done\n",
      "train loss for epoch 387 attained: 0.003094690211582929\n",
      "valid loss for epoch 387 attained: 0.0008440452365903184\n",
      "epoch 387 done\n",
      "train loss for epoch 388 attained: 0.0031385825423058122\n",
      "valid loss for epoch 388 attained: 0.000837242288980633\n",
      "epoch 388 done\n",
      "train loss for epoch 389 attained: 0.003105199459241703\n",
      "valid loss for epoch 389 attained: 0.0008382316736970097\n",
      "epoch 389 done\n",
      "train loss for epoch 390 attained: 0.0031255659196176566\n",
      "valid loss for epoch 390 attained: 0.0009054508045664988\n",
      "epoch 390 done\n",
      "train loss for epoch 391 attained: 0.0031642054018448107\n",
      "valid loss for epoch 391 attained: 0.0008434401752310805\n",
      "epoch 391 done\n",
      "train loss for epoch 392 attained: 0.0031093448706087656\n",
      "valid loss for epoch 392 attained: 0.0008132964794640429\n",
      "new best model saved\n",
      "epoch 392 done\n",
      "train loss for epoch 393 attained: 0.0031311450147768483\n",
      "valid loss for epoch 393 attained: 0.0008223348413594067\n",
      "epoch 393 done\n",
      "train loss for epoch 394 attained: 0.003068129895837046\n",
      "valid loss for epoch 394 attained: 0.000833186502859462\n",
      "epoch 394 done\n",
      "train loss for epoch 395 attained: 0.0030893242728780024\n",
      "valid loss for epoch 395 attained: 0.0008451029571006075\n",
      "epoch 395 done\n",
      "train loss for epoch 396 attained: 0.0030664601508760825\n",
      "valid loss for epoch 396 attained: 0.0008202083627111278\n",
      "epoch 396 done\n",
      "train loss for epoch 397 attained: 0.0031038397646625526\n",
      "valid loss for epoch 397 attained: 0.0008396588891628198\n",
      "epoch 397 done\n",
      "train loss for epoch 398 attained: 0.003109390767349396\n",
      "valid loss for epoch 398 attained: 0.0008133712399285287\n",
      "epoch 398 done\n",
      "train loss for epoch 399 attained: 0.0030534892866853625\n",
      "valid loss for epoch 399 attained: 0.0008083689754130319\n",
      "new best model saved\n",
      "epoch 399 done\n",
      "train loss for epoch 400 attained: 0.003086768265347928\n",
      "valid loss for epoch 400 attained: 0.0008223546246881597\n",
      "epoch 400 done\n",
      "train loss for epoch 401 attained: 0.0030753152386751026\n",
      "valid loss for epoch 401 attained: 0.0007827538065612316\n",
      "new best model saved\n",
      "epoch 401 done\n",
      "train loss for epoch 402 attained: 0.003130058030365035\n",
      "valid loss for epoch 402 attained: 0.0008479511889163405\n",
      "epoch 402 done\n",
      "train loss for epoch 403 attained: 0.0030663194265798666\n",
      "valid loss for epoch 403 attained: 0.0008571782891522162\n",
      "epoch 403 done\n",
      "train loss for epoch 404 attained: 0.003120836066955235\n",
      "valid loss for epoch 404 attained: 0.0008168819185812026\n",
      "epoch 404 done\n",
      "train loss for epoch 405 attained: 0.003224494241294451\n",
      "valid loss for epoch 405 attained: 0.000832752171845641\n",
      "epoch 405 done\n",
      "train loss for epoch 406 attained: 0.0030511318909702823\n",
      "valid loss for epoch 406 attained: 0.0008147589542204514\n",
      "epoch 406 done\n",
      "train loss for epoch 407 attained: 0.0031247076913132332\n",
      "valid loss for epoch 407 attained: 0.0008347102557308972\n",
      "epoch 407 done\n",
      "train loss for epoch 408 attained: 0.0030244271983974613\n",
      "valid loss for epoch 408 attained: 0.000797121916548349\n",
      "epoch 408 done\n",
      "train loss for epoch 409 attained: 0.0030209327378543094\n",
      "valid loss for epoch 409 attained: 0.000854544632602483\n",
      "epoch 409 done\n",
      "train loss for epoch 410 attained: 0.0030749904908589087\n",
      "valid loss for epoch 410 attained: 0.0008366210240637884\n",
      "epoch 410 done\n",
      "train loss for epoch 411 attained: 0.003060233466385398\n",
      "valid loss for epoch 411 attained: 0.0008402516541536897\n",
      "epoch 411 done\n",
      "train loss for epoch 412 attained: 0.0030731496153748594\n",
      "valid loss for epoch 412 attained: 0.0008039471213123761\n",
      "epoch 412 done\n",
      "train loss for epoch 413 attained: 0.0030518021812895313\n",
      "valid loss for epoch 413 attained: 0.0008228879596572369\n",
      "epoch 413 done\n",
      "train loss for epoch 414 attained: 0.0029928205549367703\n",
      "valid loss for epoch 414 attained: 0.0007797579382895492\n",
      "new best model saved\n",
      "epoch 414 done\n",
      "train loss for epoch 415 attained: 0.0029967446826049127\n",
      "valid loss for epoch 415 attained: 0.0008193469038815238\n",
      "epoch 415 done\n",
      "train loss for epoch 416 attained: 0.0030530433141393587\n",
      "valid loss for epoch 416 attained: 0.0008043905036174692\n",
      "epoch 416 done\n",
      "train loss for epoch 417 attained: 0.0030794316699029878\n",
      "valid loss for epoch 417 attained: 0.000797609354776796\n",
      "epoch 417 done\n",
      "train loss for epoch 418 attained: 0.00301478188339388\n",
      "valid loss for epoch 418 attained: 0.0007930778956506401\n",
      "epoch 418 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 419 attained: 0.003063370764721185\n",
      "valid loss for epoch 419 attained: 0.0008033378253458068\n",
      "epoch 419 done\n",
      "train loss for epoch 420 attained: 0.003036720991076436\n",
      "valid loss for epoch 420 attained: 0.000791629652667325\n",
      "epoch 420 done\n",
      "train loss for epoch 421 attained: 0.002997192437760532\n",
      "valid loss for epoch 421 attained: 0.0007805375353200361\n",
      "epoch 421 done\n",
      "train loss for epoch 422 attained: 0.0029580023838207126\n",
      "valid loss for epoch 422 attained: 0.0007906543251010589\n",
      "epoch 422 done\n",
      "train loss for epoch 423 attained: 0.002960102428914979\n",
      "valid loss for epoch 423 attained: 0.0007816413999535143\n",
      "epoch 423 done\n",
      "train loss for epoch 424 attained: 0.002964273589896038\n",
      "valid loss for epoch 424 attained: 0.0007931786167318933\n",
      "epoch 424 done\n",
      "train loss for epoch 425 attained: 0.0029252300882944837\n",
      "valid loss for epoch 425 attained: 0.0007924737728899345\n",
      "epoch 425 done\n",
      "train loss for epoch 426 attained: 0.0030096409827820025\n",
      "valid loss for epoch 426 attained: 0.0008268015662906691\n",
      "epoch 426 done\n",
      "train loss for epoch 427 attained: 0.0029783751742797904\n",
      "valid loss for epoch 427 attained: 0.0007918160044937395\n",
      "epoch 427 done\n",
      "train loss for epoch 428 attained: 0.0029110701943864115\n",
      "valid loss for epoch 428 attained: 0.0007624372447025962\n",
      "new best model saved\n",
      "epoch 428 done\n",
      "train loss for epoch 429 attained: 0.0029156016535125673\n",
      "valid loss for epoch 429 attained: 0.0008042490226216614\n",
      "epoch 429 done\n",
      "train loss for epoch 430 attained: 0.0029001556540606543\n",
      "valid loss for epoch 430 attained: 0.0007752375240670517\n",
      "epoch 430 done\n",
      "train loss for epoch 431 attained: 0.0029128723763278686\n",
      "valid loss for epoch 431 attained: 0.0008134904783219099\n",
      "epoch 431 done\n",
      "train loss for epoch 432 attained: 0.002948225424916018\n",
      "valid loss for epoch 432 attained: 0.0007861241610953584\n",
      "epoch 432 done\n",
      "train loss for epoch 433 attained: 0.0029820642739650793\n",
      "valid loss for epoch 433 attained: 0.0008034338607103564\n",
      "epoch 433 done\n",
      "train loss for epoch 434 attained: 0.00292386637738673\n",
      "valid loss for epoch 434 attained: 0.0007989209552761167\n",
      "epoch 434 done\n",
      "train loss for epoch 435 attained: 0.0030285299435490742\n",
      "valid loss for epoch 435 attained: 0.0008009366065380163\n",
      "epoch 435 done\n",
      "train loss for epoch 436 attained: 0.0029110486721037887\n",
      "valid loss for epoch 436 attained: 0.0007890262641012669\n",
      "epoch 436 done\n",
      "train loss for epoch 437 attained: 0.002887864007789176\n",
      "valid loss for epoch 437 attained: 0.0007858413518988527\n",
      "epoch 437 done\n",
      "train loss for epoch 438 attained: 0.0029534003551816568\n",
      "valid loss for epoch 438 attained: 0.0007993321924004704\n",
      "epoch 438 done\n",
      "train loss for epoch 439 attained: 0.002965423176647164\n",
      "valid loss for epoch 439 attained: 0.0007906827668193728\n",
      "epoch 439 done\n",
      "train loss for epoch 440 attained: 0.002990224238601513\n",
      "valid loss for epoch 440 attained: 0.0007850608235457912\n",
      "epoch 440 done\n",
      "train loss for epoch 441 attained: 0.002984570302942302\n",
      "valid loss for epoch 441 attained: 0.0007630575710209087\n",
      "epoch 441 done\n",
      "train loss for epoch 442 attained: 0.0029193521550041623\n",
      "valid loss for epoch 442 attained: 0.0007815610588295385\n",
      "epoch 442 done\n",
      "train loss for epoch 443 attained: 0.0029307534714462236\n",
      "valid loss for epoch 443 attained: 0.0008196952112484723\n",
      "epoch 443 done\n",
      "train loss for epoch 444 attained: 0.0029539390379795805\n",
      "valid loss for epoch 444 attained: 0.0008170222281478345\n",
      "epoch 444 done\n",
      "train loss for epoch 445 attained: 0.002905034620198421\n",
      "valid loss for epoch 445 attained: 0.0007578900767839514\n",
      "new best model saved\n",
      "epoch 445 done\n",
      "train loss for epoch 446 attained: 0.002900286504882388\n",
      "valid loss for epoch 446 attained: 0.0007824268177500926\n",
      "epoch 446 done\n",
      "train loss for epoch 447 attained: 0.002922012201452162\n",
      "valid loss for epoch 447 attained: 0.0007744105678284541\n",
      "epoch 447 done\n",
      "train loss for epoch 448 attained: 0.0029284787524375133\n",
      "valid loss for epoch 448 attained: 0.0007719097338849679\n",
      "epoch 448 done\n",
      "train loss for epoch 449 attained: 0.0029287783909239806\n",
      "valid loss for epoch 449 attained: 0.0008331286153406836\n",
      "epoch 449 done\n",
      "train loss for epoch 450 attained: 0.0030551348536391743\n",
      "valid loss for epoch 450 attained: 0.0007490429125027731\n",
      "new best model saved\n",
      "epoch 450 done\n",
      "train loss for epoch 451 attained: 0.0029294714040588588\n",
      "valid loss for epoch 451 attained: 0.0007755010446999222\n",
      "epoch 451 done\n",
      "train loss for epoch 452 attained: 0.002863017492927611\n",
      "valid loss for epoch 452 attained: 0.0007852406488382258\n",
      "epoch 452 done\n",
      "train loss for epoch 453 attained: 0.0029446741536958143\n",
      "valid loss for epoch 453 attained: 0.0007609832900925539\n",
      "epoch 453 done\n",
      "train loss for epoch 454 attained: 0.002872235440008808\n",
      "valid loss for epoch 454 attained: 0.0007698051704210229\n",
      "epoch 454 done\n",
      "train loss for epoch 455 attained: 0.002942606202850584\n",
      "valid loss for epoch 455 attained: 0.0007542834573541768\n",
      "epoch 455 done\n",
      "train loss for epoch 456 attained: 0.0029122082924004644\n",
      "valid loss for epoch 456 attained: 0.0007612543195136823\n",
      "epoch 456 done\n",
      "train loss for epoch 457 attained: 0.002893074430176057\n",
      "valid loss for epoch 457 attained: 0.0007818648446118459\n",
      "epoch 457 done\n",
      "train loss for epoch 458 attained: 0.0028995283573749475\n",
      "valid loss for epoch 458 attained: 0.0007762611930957064\n",
      "epoch 458 done\n",
      "train loss for epoch 459 attained: 0.0028913245696458034\n",
      "valid loss for epoch 459 attained: 0.0007596683062729426\n",
      "epoch 459 done\n",
      "train loss for epoch 460 attained: 0.0028402462630765513\n",
      "valid loss for epoch 460 attained: 0.0007701988215558231\n",
      "epoch 460 done\n",
      "train loss for epoch 461 attained: 0.0028692500054603443\n",
      "valid loss for epoch 461 attained: 0.0007466668976121582\n",
      "new best model saved\n",
      "epoch 461 done\n",
      "train loss for epoch 462 attained: 0.0028169805082143284\n",
      "valid loss for epoch 462 attained: 0.0007377783549600281\n",
      "new best model saved\n",
      "epoch 462 done\n",
      "train loss for epoch 463 attained: 0.002856040075130295\n",
      "valid loss for epoch 463 attained: 0.0007548211724497378\n",
      "epoch 463 done\n",
      "train loss for epoch 464 attained: 0.002931180875748396\n",
      "valid loss for epoch 464 attained: 0.0007810317692928948\n",
      "epoch 464 done\n",
      "train loss for epoch 465 attained: 0.0029593656872748397\n",
      "valid loss for epoch 465 attained: 0.0007818140074959956\n",
      "epoch 465 done\n",
      "train loss for epoch 466 attained: 0.0028594091345439665\n",
      "valid loss for epoch 466 attained: 0.0007882386562414467\n",
      "epoch 466 done\n",
      "train loss for epoch 467 attained: 0.002909813279984519\n",
      "valid loss for epoch 467 attained: 0.0007908710904303007\n",
      "epoch 467 done\n",
      "train loss for epoch 468 attained: 0.0028465591167332605\n",
      "valid loss for epoch 468 attained: 0.0007665499215363525\n",
      "epoch 468 done\n",
      "train loss for epoch 469 attained: 0.0029337089945329353\n",
      "valid loss for epoch 469 attained: 0.0007587042491650209\n",
      "epoch 469 done\n",
      "train loss for epoch 470 attained: 0.0028510713600553572\n",
      "valid loss for epoch 470 attained: 0.000743479176890105\n",
      "epoch 470 done\n",
      "train loss for epoch 471 attained: 0.0028770047283614986\n",
      "valid loss for epoch 471 attained: 0.0007373108674073592\n",
      "new best model saved\n",
      "epoch 471 done\n",
      "train loss for epoch 472 attained: 0.002878669598430861\n",
      "valid loss for epoch 472 attained: 0.0007485213063773699\n",
      "epoch 472 done\n",
      "train loss for epoch 473 attained: 0.0028824193359469064\n",
      "valid loss for epoch 473 attained: 0.0007526906338171102\n",
      "epoch 473 done\n",
      "train loss for epoch 474 attained: 0.0028218601437401958\n",
      "valid loss for epoch 474 attained: 0.0008181536250049248\n",
      "epoch 474 done\n",
      "train loss for epoch 475 attained: 0.002820387795509305\n",
      "valid loss for epoch 475 attained: 0.0007307770792976953\n",
      "new best model saved\n",
      "epoch 475 done\n",
      "train loss for epoch 476 attained: 0.0028364961108309217\n",
      "valid loss for epoch 476 attained: 0.0007466286260751076\n",
      "epoch 476 done\n",
      "train loss for epoch 477 attained: 0.002884869732952211\n",
      "valid loss for epoch 477 attained: 0.0007359724986599758\n",
      "epoch 477 done\n",
      "train loss for epoch 478 attained: 0.002799936533847358\n",
      "valid loss for epoch 478 attained: 0.0007421457339660265\n",
      "epoch 478 done\n",
      "train loss for epoch 479 attained: 0.002804889234539587\n",
      "valid loss for epoch 479 attained: 0.0007494740202673711\n",
      "epoch 479 done\n",
      "train loss for epoch 480 attained: 0.0027838247406180017\n",
      "valid loss for epoch 480 attained: 0.0007516694604419172\n",
      "epoch 480 done\n",
      "train loss for epoch 481 attained: 0.002772976593405474\n",
      "valid loss for epoch 481 attained: 0.0007187147348304279\n",
      "new best model saved\n",
      "epoch 481 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss for epoch 482 attained: 0.0028201727036503144\n",
      "valid loss for epoch 482 attained: 0.0007238740072352812\n",
      "epoch 482 done\n",
      "train loss for epoch 483 attained: 0.0027501375079737045\n",
      "valid loss for epoch 483 attained: 0.0007210492622107267\n",
      "epoch 483 done\n",
      "train loss for epoch 484 attained: 0.0027712786686606705\n",
      "valid loss for epoch 484 attained: 0.000730902400391642\n",
      "epoch 484 done\n",
      "train loss for epoch 485 attained: 0.002810810452501755\n",
      "valid loss for epoch 485 attained: 0.0007330947773880325\n",
      "epoch 485 done\n",
      "train loss for epoch 486 attained: 0.0028227570219314657\n",
      "valid loss for epoch 486 attained: 0.0007353934852289967\n",
      "epoch 486 done\n",
      "train loss for epoch 487 attained: 0.002858413616195321\n",
      "valid loss for epoch 487 attained: 0.0007323326426558197\n",
      "epoch 487 done\n",
      "train loss for epoch 488 attained: 0.0028001467435387895\n",
      "valid loss for epoch 488 attained: 0.0007306467305170372\n",
      "epoch 488 done\n",
      "train loss for epoch 489 attained: 0.0028156330808997154\n",
      "valid loss for epoch 489 attained: 0.0007798337828717194\n",
      "epoch 489 done\n",
      "train loss for epoch 490 attained: 0.002846634881279897\n",
      "valid loss for epoch 490 attained: 0.0007364136399701238\n",
      "epoch 490 done\n",
      "train loss for epoch 491 attained: 0.0027836354056489654\n",
      "valid loss for epoch 491 attained: 0.0007491343712899834\n",
      "epoch 491 done\n",
      "train loss for epoch 492 attained: 0.0027760244483943097\n",
      "valid loss for epoch 492 attained: 0.0007085400429787114\n",
      "new best model saved\n",
      "epoch 492 done\n",
      "train loss for epoch 493 attained: 0.0027806969155790284\n",
      "valid loss for epoch 493 attained: 0.0007318959251279011\n",
      "epoch 493 done\n",
      "train loss for epoch 494 attained: 0.0028016951619065367\n",
      "valid loss for epoch 494 attained: 0.0007173592821345665\n",
      "epoch 494 done\n",
      "train loss for epoch 495 attained: 0.00283679278800264\n",
      "valid loss for epoch 495 attained: 0.0007306054612854496\n",
      "epoch 495 done\n",
      "train loss for epoch 496 attained: 0.0027663168948492967\n",
      "valid loss for epoch 496 attained: 0.000718606730515603\n",
      "epoch 496 done\n",
      "train loss for epoch 497 attained: 0.0028488994284998626\n",
      "valid loss for epoch 497 attained: 0.0007600669923704118\n",
      "epoch 497 done\n",
      "train loss for epoch 498 attained: 0.002764874152489938\n",
      "valid loss for epoch 498 attained: 0.0007165503266151063\n",
      "epoch 498 done\n",
      "train loss for epoch 499 attained: 0.002821617978042923\n",
      "valid loss for epoch 499 attained: 0.0007419145404128358\n",
      "epoch 499 done\n",
      "finished looping epochs\n",
      "best valid loss = 0.0007085400429787114, epoch 492\n",
      "best model loaded and saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a3f9a1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a52131ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot saved\n",
      "dataframe saved\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a5218aef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "run_training(model=model, modelpath=model_path, figpath=fig_path, fig2path = fig2_path, dfpath=df_path, trainset=trainset, \n",
    "      validsize=valid_size, numepochs=n_epochs, batchsize=batch_size, seed=seed)\n",
    "\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.2028e-01, -4.1258e-02,  7.1257e-01],\n",
       "         [-4.1420e-02, -6.5168e-02,  1.0124e+00],\n",
       "         [ 7.3406e-02,  2.4579e-02, -6.6968e-01],\n",
       "         [-2.2512e-02, -5.6759e-02, -7.4806e-01],\n",
       "         [ 9.3764e-01,  1.5452e-02, -5.7616e-05],\n",
       "         [-7.9379e-02,  1.6258e-02, -6.1123e-01],\n",
       "         [ 6.3039e-01,  6.1111e-02, -7.5472e-02],\n",
       "         [-1.3628e-01, -8.1480e-01, -3.5047e-04],\n",
       "         [ 6.8380e-01, -5.8541e-02, -5.9847e-03],\n",
       "         [ 6.3130e-02,  4.7420e-01, -6.0040e-03],\n",
       "         [-4.4007e-03,  4.7305e-01, -1.6130e-03],\n",
       "         [ 3.7318e-02, -7.1574e-02,  8.9381e-01],\n",
       "         [-2.0184e-01,  6.4543e-01,  2.3740e-03],\n",
       "         [-1.2250e-01, -3.2162e-01, -3.0804e-02],\n",
       "         [ 7.1145e-02, -2.8883e-01,  2.9344e-02],\n",
       "         [ 2.6705e-02,  7.2184e-02,  8.9124e-01],\n",
       "         [-3.3327e-03,  7.4843e-01, -4.4215e-03],\n",
       "         [-3.7683e-01,  8.2216e-02,  2.4984e-03],\n",
       "         [ 5.1090e-03, -5.5402e-02,  8.0347e-01],\n",
       "         [-4.4125e-01, -9.1594e-02, -8.5676e-03],\n",
       "         [ 2.1646e-01,  4.5726e-04, -6.0656e-01],\n",
       "         [-2.2247e-02,  8.7216e-02,  9.1894e-01],\n",
       "         [ 7.9761e-02,  8.0232e-01, -1.0371e-01],\n",
       "         [-4.4942e-03, -2.6665e-03, -8.1787e-01],\n",
       "         [-6.4044e-02,  6.7557e-02, -9.2123e-01],\n",
       "         [ 1.1412e-01,  9.2012e-01,  2.0564e-01],\n",
       "         [ 6.4773e-01, -4.0234e-01, -7.8232e-02],\n",
       "         [-4.4555e-01, -5.2994e-01,  1.7276e-02],\n",
       "         [-9.1549e-02, -4.6331e-03,  7.3795e-01],\n",
       "         [ 8.4033e-01,  2.1750e-02,  1.0045e-03],\n",
       "         [-2.1996e-02,  1.2406e-01,  7.6058e-01],\n",
       "         [ 7.1179e-02, -1.5119e-01,  6.2953e-01],\n",
       "         [-7.6879e-01,  4.9602e-01,  1.1207e-01],\n",
       "         [ 1.0969e-01, -2.9068e-01,  4.8562e-02],\n",
       "         [ 3.1044e-04,  6.0338e-02,  7.0529e-01],\n",
       "         [-5.8614e-02, -6.1535e-01, -4.3731e-02],\n",
       "         [ 8.1114e-02,  9.2260e-02, -1.3749e-01],\n",
       "         [-1.1224e-01, -1.4989e-04,  4.8618e-01],\n",
       "         [-2.0533e-02,  1.9245e-03, -9.8343e-01],\n",
       "         [-1.7461e-01,  8.3960e-01,  5.4445e-03],\n",
       "         [-1.0725e-02,  4.8427e-02, -5.5659e-01],\n",
       "         [-9.0331e-03, -4.9429e-02, -7.0557e-01],\n",
       "         [-1.5732e-01, -8.5134e-02,  2.9774e-02],\n",
       "         [ 2.0621e-03,  1.3815e-02,  6.3770e-01],\n",
       "         [ 6.7061e-01, -1.4026e-01, -8.5333e-03],\n",
       "         [-3.1985e-01, -2.2136e-02,  1.0014e-01],\n",
       "         [-9.7973e-04,  5.5283e-02,  8.8796e-01],\n",
       "         [ 6.2488e-01,  6.2054e-02,  9.7397e-02],\n",
       "         [-3.4074e-02,  6.3015e-02, -8.0584e-01],\n",
       "         [-9.4570e-02, -5.8469e-01, -1.9371e-01]]), Parameter containing:\n",
       " tensor([ 0.0657, -0.3217, -0.4014, -0.4611,  0.3560,  0.1731, -0.6195,\n",
       "         -0.4645,  0.7366,  0.5351,  0.7809, -0.8304, -0.0219,  0.9238,\n",
       "          0.9820, -0.8298, -0.7364,  0.3905, -1.0876, -0.4715,  0.8695,\n",
       "         -0.2767, -0.1399,  0.4959, -0.5420, -0.1374, -0.0465, -0.1917,\n",
       "         -0.6586, -0.2152,  0.3912,  0.3199,  0.0598,  0.7536, -0.9487,\n",
       "          0.1223, -0.5054,  0.5584, -0.9701,  0.7625, -0.7609, -0.9524,\n",
       "          0.6164,  0.1895, -0.6963,  0.7487,  0.0564, -0.6287, -0.0850,\n",
       "          0.0594]), Parameter containing:\n",
       " tensor([[-4.2102e-03,  1.1163e-02, -9.7448e-03,  2.3307e-02,  3.6843e-01,\n",
       "           1.3913e-02,  2.7826e-01,  8.3061e-06,  4.2654e-01,  1.2176e-02,\n",
       "          -4.8983e-02,  1.4617e-02, -1.3007e-02, -1.2195e-01, -2.1953e-01,\n",
       "           6.8807e-04, -7.2626e-03, -2.2045e-01, -1.8544e-02,  2.8752e-01,\n",
       "           7.3811e-03,  9.2402e-03,  1.7982e-03, -2.7896e-02, -3.2619e-02,\n",
       "           3.7640e-02,  2.3089e-01, -6.6919e-03,  1.3741e-03,  4.1412e-01,\n",
       "          -1.9833e-02,  1.9120e-02, -1.5005e-01, -2.0330e-02,  4.4548e-04,\n",
       "          -2.3125e-02, -2.2617e-02, -2.3476e-02,  9.9347e-03, -8.7960e-03,\n",
       "           1.9435e-03, -1.1724e-03, -2.6118e-02,  8.2676e-02,  3.5013e-01,\n",
       "          -2.0210e-01, -2.7352e-02,  2.3630e-01, -3.0020e-02, -3.8490e-02],\n",
       "         [-3.1802e-03, -1.7478e-03, -8.4417e-03, -8.6796e-02,  3.0555e-03,\n",
       "           1.0291e-02,  5.3253e-03,  2.8219e-01,  1.0412e-02,  4.1710e-01,\n",
       "           2.1961e-01, -4.9131e-03,  2.1979e-01, -1.8071e-01, -1.6453e-01,\n",
       "           7.9258e-03,  5.5664e-01,  2.5820e-02, -7.4532e-03, -2.3549e-02,\n",
       "           2.0402e-03,  1.1680e-02,  2.7327e-01, -2.2717e-02,  6.0798e-02,\n",
       "           2.2303e-01, -9.8890e-02, -5.6325e-02,  5.4570e-03,  2.9165e-03,\n",
       "           6.4867e-02, -3.2150e-02,  6.5914e-02, -2.2320e-01,  4.3144e-03,\n",
       "           6.5632e-02, -7.8989e-02, -9.2719e-03,  3.4740e-03,  2.4020e-01,\n",
       "          -8.1378e-03,  1.3645e-02, -2.6802e-01, -3.3382e-02, -2.2211e-02,\n",
       "          -1.2646e-01, -1.6146e-02,  1.5497e-03,  1.5742e-02, -1.2470e-01],\n",
       "         [ 1.4036e-01,  3.9436e-01,  4.1714e-01,  4.4090e-01, -6.5341e-03,\n",
       "           3.3489e-01, -1.1542e-02,  5.4667e-03, -1.7533e-02, -4.9305e-02,\n",
       "          -3.7238e-01,  4.2103e-01,  4.8521e-03, -2.2362e-01, -3.0961e-01,\n",
       "           4.1909e-01, -9.0409e-03, -1.0249e-01,  6.2309e-01,  1.2004e-02,\n",
       "           5.0717e-02,  3.4207e-01, -4.2119e-02,  5.3307e-01,  3.4157e-01,\n",
       "          -8.8663e-02, -1.1517e-03,  7.3859e-03,  2.9913e-01, -4.4102e-03,\n",
       "           8.1516e-02,  1.9960e-02, -1.0648e-03, -2.8233e-01,  5.8255e-01,\n",
       "           1.0767e-01, -9.1436e-02,  2.4888e-01,  6.7418e-01,  9.1490e-03,\n",
       "           7.0278e-01,  6.8807e-01, -3.1875e-01,  4.3168e-01,  4.9459e-02,\n",
       "          -9.4955e-02,  4.3070e-01,  5.2482e-03,  3.7307e-01,  5.5545e-02]]), Parameter containing:\n",
       " tensor([-0.0606, -0.1344, -0.4352])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output = [-3.76401146e+02  2.45290728e-01  2.55478347e-01]\n",
      "target output = [0.25 0.25 0.25]\n",
      "error = 86983.85621731936%\n",
      "accuracy = -86883.85621731936%\n"
     ]
    }
   ],
   "source": [
    "# testing the model with a chosen vector\n",
    "testvec = np.array([0.5,0.5,0.5])\n",
    "\n",
    "# standardize the input vector\n",
    "test_input = (testvec-inputMeans)/inputStdDevs\n",
    "test_input = torch.tensor(test_input).float()\n",
    "\n",
    "# put standardized input vector through model\n",
    "model.eval()\n",
    "test_output = model(test_input)\n",
    "test_output = test_output.detach().numpy()\n",
    "\n",
    "# unstandardizing the output\n",
    "test_result = (test_output*outputStdDevs)+outputMeans\n",
    "\n",
    "print('model output = {}'.format(test_result))\n",
    "\n",
    "# compare to target output\n",
    "x_targ = (testvec[0])**2\n",
    "y_targ = (testvec[1])**2\n",
    "z_targ = (testvec[2])**2\n",
    "\n",
    "targ_vec = np.array([x_targ, y_targ, z_targ])\n",
    "\n",
    "print('target output = {}'.format(targ_vec))\n",
    "\n",
    "# measure accuracy\n",
    "diff = np.linalg.norm(targ_vec - test_result)\n",
    "mag = np.linalg.norm(targ_vec)\n",
    "error = (diff/mag)*100\n",
    "acc = 100 - error\n",
    "print('error = {}%'.format(error))\n",
    "print('accuracy = {}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
