{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'vector_stand_dataset.npz'\n",
    "batch_size = 250\n",
    "n_epochs = 500\n",
    "valid_size = 2000\n",
    "model_path = 'v_stand_model'\n",
    "fig_path = 'v_stand_fig.png'\n",
    "fig2_path = 'v_stand_fig_zoom.png'\n",
    "df_path = 'v_stand_df'\n",
    "seed = np.random.randint(low=0, high=1000000, size=1)\n",
    "std_scheme = 0    #choose 0 for none, 1 for element-wise, 2 for vector-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_std(infile):\n",
    "    \n",
    "    # load data\n",
    "    npfile = np.load(infile)\n",
    "    inputs = npfile['inputs']\n",
    "    outputs = npfile['outputs']\n",
    "    \n",
    "    # convert to tensors\n",
    "    inputs = torch.from_numpy(inputs).float()\n",
    "    outputs = torch.from_numpy(outputs).float()\n",
    "    \n",
    "    # return dataset\n",
    "    trainset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    \n",
    "    return trainset\n",
    "\n",
    "\n",
    "def std_elementwise(infile):\n",
    "    \n",
    "    # load data\n",
    "    npfile = np.load(infile)\n",
    "    inputs = npfile['inputs']\n",
    "    outputs = npfile['outputs']\n",
    "\n",
    "    # standardize inputs, outputs by element and covert to tensors\n",
    "    inputMeans = inputs[0:int(inputs.shape[0]),:].mean(axis=0)\n",
    "    inputStdDevs = inputs[0:int(inputs.shape[0]),:].std(axis=0)\n",
    "    inputs = (inputs-inputMeans)/inputStdDevs\n",
    "    inputs = torch.from_numpy(inputs).float()\n",
    "\n",
    "    outputMeans = outputs[0:int(outputs.shape[0]),:].mean(axis=0)\n",
    "    outputStdDevs = outputs[0:int(outputs.shape[0]),:].std(axis=0)\n",
    "    outputs = (outputs-outputMeans)/outputStdDevs\n",
    "    outputs = torch.from_numpy(outputs).float()\n",
    "    \n",
    "    # return dataset\n",
    "    trainset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    \n",
    "    return trainset\n",
    "    \n",
    "\n",
    "def std_vectorwise(infile):\n",
    "    \n",
    "    # load data\n",
    "    npfile = np.load(infile)\n",
    "    inputs = npfile['inputs']\n",
    "    outputs = npfile['outputs']\n",
    "    \n",
    "    # standardize inputs, outputs by vector and covert to tensors\n",
    "    inputMean = np.mean(inputs)\n",
    "    inputStdDev = np.mean(inputs)\n",
    "    inputs = (inputs-inputMean)/inputStdDev\n",
    "    inputs = torch.from_numpy(inputs).float()\n",
    "\n",
    "    outputMean = np.mean(outputs)\n",
    "    outputStdDev = np.mean(outputs)\n",
    "    outputs = (outputs-outputMean)/outputStdDev\n",
    "    outputs = torch.from_numpy(outputs).float()\n",
    "    \n",
    "    # return dataset\n",
    "    trainset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    \n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform the selected standardization scheme\n",
    "if std_scheme == 0:\n",
    "    trainset = no_std(infile)  \n",
    "elif std_scheme == 1:\n",
    "    trainset = std_elementwise(infile)\n",
    "elif std_scheme == 2:\n",
    "    trainset = std_vectorwise(infile)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = OrderedDict([('lin1', nn.Linear(6, 3)),('relu1', nn.ReLU()),('lin2', nn.Linear(3, 3))]) \n",
    "\n",
    "model = nn.Sequential(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the training process for one epoch, returns training loss for given epoch\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # put model into train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (inputs, outputs) in enumerate(loader):\n",
    "        inputs_var = inputs\n",
    "        outputs_var = outputs\n",
    "        \n",
    "        # get model output & loss for each given input\n",
    "        model_outputs = model(inputs_var)\n",
    "        loss = criterion(model_outputs, outputs_var)\n",
    "\n",
    "        # record cummulative loss\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "        # gradient, optimizer steps\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return running_train_loss\n",
    "\n",
    "\n",
    "# defines the validation process for one epoch, returns validation loss for given epoch\n",
    "def validate(model, loader, criterion):\n",
    "    running_valid_loss = 0.0\n",
    "\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (inputs, outputs) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            inputs_var = inputs\n",
    "            outputs_var = outputs\n",
    "\n",
    "            # get model output & loss for each given input\n",
    "            model_outputs = model(inputs_var)\n",
    "            loss = criterion(model_outputs, outputs_var)\n",
    "\n",
    "        # record cummulative loss\n",
    "        running_valid_loss += loss.item()\n",
    "\n",
    "    return running_valid_loss\n",
    "\n",
    "\n",
    "# runs training and validation process over all epochs, returns results\n",
    "def run_training(model, modelpath, figpath, fig2path, dfpath, trainset, validsize, numepochs, batchsize, seed):\n",
    "    # set seed\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # create validation split\n",
    "    indices = torch.randperm(len(trainset))\n",
    "    train_indices = indices[:len(indices) - valid_size]\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "    valid_indices = indices[len(indices) - valid_size:]\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "    # define data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=valid_sampler)\n",
    "  \n",
    "    # set criterion, optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # store results\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    train_loss_results = []\n",
    "    valid_loss_results = []\n",
    "    epochs = []\n",
    "    \n",
    "    # train model\n",
    "    for epoch in enumerate(range(n_epochs)):\n",
    "        trainloss = train(model=model,loader=train_loader,criterion=criterion,optimizer=optimizer)\n",
    "        print('train loss for epoch {index} attained: {loss}'.format(index=epoch[0], loss=trainloss))\n",
    "        \n",
    "        validloss = validate(model=model,loader=valid_loader,criterion=criterion)\n",
    "        print('valid loss for epoch {index} attained: {loss}'.format(index=epoch[0], loss=validloss))\n",
    "        \n",
    "        train_loss_results.append(trainloss)\n",
    "        valid_loss_results.append(validloss)\n",
    "        epochs.append(epoch[0]+1)\n",
    "        \n",
    "        # check if model is the best, save if best\n",
    "        if epoch[0] == 0:\n",
    "            bestloss = validloss\n",
    "\n",
    "        if epoch[0] > 0:\n",
    "            if validloss < bestloss:\n",
    "                bestloss = validloss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_epoch = epoch[0]\n",
    "                print('new best model saved')\n",
    "                \n",
    "        print('epoch {index} done'.format(index=epoch[0]))\n",
    "        \n",
    "    print('finished looping epochs')\n",
    "    print('best valid loss = {}, epoch {}'.format(bestloss, best_epoch))\n",
    "\n",
    "    # load and save the best model\n",
    "    torch.save(best_model, model_path)\n",
    "    print('best model loaded and saved')\n",
    "\n",
    "    # plot training & validation loss vs. epoch\n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(epochs, train_loss_results)\n",
    "    plt.plot(epochs, valid_loss_results)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    fig1.savefig(fig_path)\n",
    "    print('plot saved')\n",
    "    \n",
    "    # plot training & validation loss vs. epoch -- scale 2\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(epochs, train_loss_results)\n",
    "    plt.plot(epochs, valid_loss_results)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0,(bestloss*100))\n",
    "    plt.show()\n",
    "    fig2.savefig('fig2_path')\n",
    "    print('plot saved')\n",
    "    \n",
    "    # create dataframe of epochs, losses\n",
    "    d = {'trainloss':train_loss_results, 'validloss':valid_loss_results}\n",
    "    df = pd.DataFrame(d, index=epochs)\n",
    "    df.to_csv(df_path)\n",
    "    print('dataframe saved')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "run_training(model=model, modelpath=model_path, figpath=fig_path, fig2path = fig2_path, dfpath=df_path, trainset=trainset, \n",
    "      validsize=valid_size, numepochs=n_epochs, batchsize=batch_size, seed=seed)\n",
    "\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting model parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model with a chosen vector\n",
    "vector1 = np.array([0.5,0.5,0.5])\n",
    "vector2 = np.array([0.5,0.5,0.5])\n",
    "\n",
    "test_input = np.append(vector1,vector2)\n",
    "\n",
    "# standardize the input vector\n",
    "if std_scheme == 0:\n",
    "    test_input = torch.tensor(test_input).float()\n",
    "\n",
    "elif std_scheme == 1:\n",
    "    npfile = np.load(infile)\n",
    "    inputs = npfile['inputs']\n",
    "    \n",
    "    inputMeans = inputs[0:int(inputs.shape[0]),:].mean(axis=0)\n",
    "    inputStdDevs = inputs[0:int(inputs.shape[0]),:].std(axis=0)\n",
    "    test_input = (test_input-inputMeans)/inputStdDevs\n",
    "    test_input = torch.tensor(test_input).float()\n",
    "    \n",
    "elif std_scheme == 2:\n",
    "    npfile = np.load(infile)\n",
    "    inputs = npfile['inputs']\n",
    "    \n",
    "    inputMean = np.mean(inputs)\n",
    "    inputStdDev = np.mean(inputs)\n",
    "    test_input = (test_input-inputMean)/inputStdDev\n",
    "    test_input = torch.tensor(test_input).float()\n",
    "\n",
    "# put standardized input vector through model\n",
    "model.eval()\n",
    "test_output = model(test_input)\n",
    "test_output = test_output.detach().numpy()\n",
    "\n",
    "# unstandardizing the output\n",
    "if std_scheme == 0:\n",
    "    test_result = test_output  \n",
    "    \n",
    "elif std_scheme == 1:\n",
    "    npfile = np.load(infile)\n",
    "    outputs = npfile['outputs']\n",
    "    \n",
    "    outputMeans = outputs[0:int(outputs.shape[0]),:].mean(axis=0)\n",
    "    outputStdDevs = outputs[0:int(outputs.shape[0]),:].std(axis=0)\n",
    "    \n",
    "    test_result = (test_output*outputStdDevs)+outputMeans\n",
    "    \n",
    "elif std_scheme == 2:\n",
    "    npfile = np.load(infile)\n",
    "    outputs = npfile['outputs']\n",
    "    \n",
    "    outputMean = np.mean(outputs)\n",
    "    outputStdDev = np.mean(outputs)\n",
    "    \n",
    "    test_result = (test_output*outputStdDev)+outputMean\n",
    "    \n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
